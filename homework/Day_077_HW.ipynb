{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
    "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 10:50:10.363795 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0803 10:50:10.394546 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0803 10:50:10.397027 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
    "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
    "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(units=128, activation=\"relu\")(x)\n",
    "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "\n",
    "    return model\n",
    "model = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 10:50:11.518265 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0803 10:50:11.526696 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n",
    "model = build_mlp()\n",
    "# 用 Keras 內建方法檢視模型各層參數量\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 10:50:14.262511 18980 deprecation.py:323] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0803 10:50:14.310127 18980 deprecation_wrapper.py:119] From C:\\Users\\an_fl\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.9300 - acc: 0.3019 - val_loss: 1.8010 - val_acc: 0.3493\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.7115 - acc: 0.3871 - val_loss: 1.6792 - val_acc: 0.3899\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6159 - acc: 0.4221 - val_loss: 1.5830 - val_acc: 0.4298\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.5552 - acc: 0.4436 - val_loss: 1.5530 - val_acc: 0.4445\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.5006 - acc: 0.4638 - val_loss: 1.5145 - val_acc: 0.4622\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.4591 - acc: 0.4817 - val_loss: 1.4844 - val_acc: 0.4730\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.4296 - acc: 0.4917 - val_loss: 1.4381 - val_acc: 0.4892\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.4099 - acc: 0.4960 - val_loss: 1.4542 - val_acc: 0.4883\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 1.3748 - acc: 0.5099 - val_loss: 1.4846 - val_acc: 0.4656\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 1.3572 - acc: 0.5148 - val_loss: 1.3986 - val_acc: 0.4985\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 1.3287 - acc: 0.5258 - val_loss: 1.4184 - val_acc: 0.4996\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 1.3030 - acc: 0.5365 - val_loss: 1.3994 - val_acc: 0.5059\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 1.2794 - acc: 0.5423 - val_loss: 1.3956 - val_acc: 0.5020\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 1.2540 - acc: 0.5510 - val_loss: 1.3980 - val_acc: 0.5045\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.2416 - acc: 0.5559 - val_loss: 1.3716 - val_acc: 0.5107\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 1.2105 - acc: 0.5682 - val_loss: 1.3657 - val_acc: 0.5148\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.1871 - acc: 0.5760 - val_loss: 1.3648 - val_acc: 0.5212\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.1668 - acc: 0.5828 - val_loss: 1.3997 - val_acc: 0.5085\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.1449 - acc: 0.5901 - val_loss: 1.3738 - val_acc: 0.5153 0.\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.1300 - acc: 0.5955 - val_loss: 1.3716 - val_acc: 0.5207\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.1110 - acc: 0.6036 - val_loss: 1.3959 - val_acc: 0.5131\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0865 - acc: 0.6119 - val_loss: 1.3866 - val_acc: 0.5203\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.0695 - acc: 0.6179 - val_loss: 1.3687 - val_acc: 0.5219\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0486 - acc: 0.6243 - val_loss: 1.4130 - val_acc: 0.5229\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.0306 - acc: 0.6344 - val_loss: 1.4116 - val_acc: 0.5146\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.0139 - acc: 0.6365 - val_loss: 1.3923 - val_acc: 0.5305\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.9937 - acc: 0.6467 - val_loss: 1.4920 - val_acc: 0.5040\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.9800 - acc: 0.6481 - val_loss: 1.4176 - val_acc: 0.5210\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.9522 - acc: 0.6603 - val_loss: 1.4161 - val_acc: 0.5243\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 0.9353 - acc: 0.6651 - val_loss: 1.4444 - val_acc: 0.5256\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.9297 - acc: 0.6696 - val_loss: 1.4414 - val_acc: 0.5250\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.9035 - acc: 0.6763 - val_loss: 1.4905 - val_acc: 0.5150\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.8872 - acc: 0.6824 - val_loss: 1.4950 - val_acc: 0.5224\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.8702 - acc: 0.6890 - val_loss: 1.4940 - val_acc: 0.5250\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.8580 - acc: 0.6919 - val_loss: 1.5094 - val_acc: 0.5256\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.8420 - acc: 0.6994 - val_loss: 1.5260 - val_acc: 0.5208\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.8169 - acc: 0.7072 - val_loss: 1.5505 - val_acc: 0.5182\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.8057 - acc: 0.7118 - val_loss: 1.5833 - val_acc: 0.5225\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.7866 - acc: 0.7189 - val_loss: 1.5879 - val_acc: 0.5143\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7706 - acc: 0.7250 - val_loss: 1.6148 - val_acc: 0.5194\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.7610 - acc: 0.7292 - val_loss: 1.6360 - val_acc: 0.5133\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.7281 - acc: 0.7411 - val_loss: 1.6082 - val_acc: 0.5308\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.7233 - acc: 0.7420 - val_loss: 1.7071 - val_acc: 0.5142\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.7246 - acc: 0.7411 - val_loss: 1.6920 - val_acc: 0.5104\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.7007 - acc: 0.7487 - val_loss: 1.6937 - val_acc: 0.5184\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.6812 - acc: 0.7556 - val_loss: 1.7027 - val_acc: 0.5214\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.6638 - acc: 0.7615 - val_loss: 1.6957 - val_acc: 0.5212\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.6615 - acc: 0.7643 - val_loss: 1.7927 - val_acc: 0.5173\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.6429 - acc: 0.7699 - val_loss: 1.7480 - val_acc: 0.5241\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.6339 - acc: 0.7735 - val_loss: 1.8249 - val_acc: 0.5136\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.6071 - acc: 0.7830 - val_loss: 1.8417 - val_acc: 0.5214oss: 0.6063 - acc: \n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.6078 - acc: 0.7820 - val_loss: 1.8779 - val_acc: 0.5206\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5969 - acc: 0.7867 - val_loss: 1.9186 - val_acc: 0.5063\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5792 - acc: 0.7950 - val_loss: 1.9666 - val_acc: 0.5060\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.5755 - acc: 0.7938 - val_loss: 1.9476 - val_acc: 0.5033\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5667 - acc: 0.7979 - val_loss: 1.9486 - val_acc: 0.5090\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5412 - acc: 0.8075 - val_loss: 1.9627 - val_acc: 0.5171\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5420 - acc: 0.8070 - val_loss: 2.0026 - val_acc: 0.5146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.5277 - acc: 0.8121 - val_loss: 2.0564 - val_acc: 0.5082\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5428 - acc: 0.8056 - val_loss: 2.1583 - val_acc: 0.5016\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.5149 - acc: 0.8177 - val_loss: 2.1290 - val_acc: 0.5091\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.4913 - acc: 0.8248 - val_loss: 2.1266 - val_acc: 0.5098\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.4795 - acc: 0.8286 - val_loss: 2.1216 - val_acc: 0.5116\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.4620 - acc: 0.8352 - val_loss: 2.1599 - val_acc: 0.5057\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.4809 - acc: 0.8280 - val_loss: 2.1737 - val_acc: 0.5054\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.4678 - acc: 0.8332 - val_loss: 2.2162 - val_acc: 0.5071\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.4610 - acc: 0.8317 - val_loss: 2.3149 - val_acc: 0.4996\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.4544 - acc: 0.8362 - val_loss: 2.3003 - val_acc: 0.5100\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.4351 - acc: 0.8437 - val_loss: 2.3366 - val_acc: 0.5106\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.4300 - acc: 0.8466 - val_loss: 2.3718 - val_acc: 0.4982\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.4344 - acc: 0.8444 - val_loss: 2.3781 - val_acc: 0.5043\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.4287 - acc: 0.8448 - val_loss: 2.4210 - val_acc: 0.5074\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.4018 - acc: 0.8574 - val_loss: 2.3762 - val_acc: 0.5099\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.3858 - acc: 0.8622 - val_loss: 2.4189 - val_acc: 0.5095\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.4111 - acc: 0.8526 - val_loss: 2.5231 - val_acc: 0.5052\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.3957 - acc: 0.8588 - val_loss: 2.5763 - val_acc: 0.5005\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.3877 - acc: 0.8619 - val_loss: 2.5648 - val_acc: 0.5067\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.3813 - acc: 0.8629 - val_loss: 2.5489 - val_acc: 0.5048\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3792 - acc: 0.8642 - val_loss: 2.6643 - val_acc: 0.4985\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.3877 - acc: 0.8608 - val_loss: 2.6059 - val_acc: 0.5071\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.3662 - acc: 0.8680 - val_loss: 2.7261 - val_acc: 0.5005\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.3618 - acc: 0.8690 - val_loss: 2.5962 - val_acc: 0.5115\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3396 - acc: 0.8782 - val_loss: 2.7170 - val_acc: 0.5056\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3471 - acc: 0.8754 - val_loss: 2.7600 - val_acc: 0.5035: 0.\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.3512 - acc: 0.8724 - val_loss: 2.7594 - val_acc: 0.5011\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3286 - acc: 0.8815 - val_loss: 2.7617 - val_acc: 0.4944\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3313 - acc: 0.8820 - val_loss: 2.7988 - val_acc: 0.4983s\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3353 - acc: 0.8803 - val_loss: 2.8525 - val_acc: 0.5039\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3081 - acc: 0.8888 - val_loss: 2.9430 - val_acc: 0.4998\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.3326 - acc: 0.8793 - val_loss: 2.9209 - val_acc: 0.4946\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3092 - acc: 0.8881 - val_loss: 2.8875 - val_acc: 0.4994\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.2947 - acc: 0.8950 - val_loss: 2.9282 - val_acc: 0.4947\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.3076 - acc: 0.8886 - val_loss: 2.9709 - val_acc: 0.4946\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2961 - acc: 0.8923 - val_loss: 3.0145 - val_acc: 0.4968\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2868 - acc: 0.8958 - val_loss: 3.0821 - val_acc: 0.4933\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3245 - acc: 0.8824 - val_loss: 3.0206 - val_acc: 0.4980\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.3090 - acc: 0.8883 - val_loss: 3.0787 - val_acc: 0.4950s - loss: 0.3043 - a - ETA: 1s - loss: \n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.2922 - acc: 0.8952 - val_loss: 3.0600 - val_acc: 0.5017\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.2892 - acc: 0.8947 - val_loss: 3.1727 - val_acc: 0.4898\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.3114 - acc: 0.8880 - val_loss: 3.0734 - val_acc: 0.4964\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2753 - acc: 0.9007 - val_loss: 3.1757 - val_acc: 0.5029\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2549 - acc: 0.9107 - val_loss: 3.2014 - val_acc: 0.4997\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2942 - acc: 0.8931 - val_loss: 3.2192 - val_acc: 0.4984\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.3003 - acc: 0.8898 - val_loss: 3.2715 - val_acc: 0.4895\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2358 - acc: 0.9155 - val_loss: 3.2236 - val_acc: 0.4997\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2604 - acc: 0.9060 - val_loss: 3.2134 - val_acc: 0.5028\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2607 - acc: 0.9058 - val_loss: 3.3757 - val_acc: 0.4954\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2946 - acc: 0.8935 - val_loss: 3.2620 - val_acc: 0.4982\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2559 - acc: 0.9084 - val_loss: 3.3720 - val_acc: 0.4964\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2528 - acc: 0.9086 - val_loss: 3.2948 - val_acc: 0.4869\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2542 - acc: 0.9089 - val_loss: 3.2517 - val_acc: 0.4989\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.2361 - acc: 0.9152 - val_loss: 3.4006 - val_acc: 0.4932\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2692 - acc: 0.9024 - val_loss: 3.4204 - val_acc: 0.4891\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2812 - acc: 0.8986 - val_loss: 3.3615 - val_acc: 0.4915\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2338 - acc: 0.9170 - val_loss: 3.4095 - val_acc: 0.4934\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2163 - acc: 0.9226 - val_loss: 3.4824 - val_acc: 0.4933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2413 - acc: 0.9146 - val_loss: 3.4581 - val_acc: 0.4939\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2397 - acc: 0.9133 - val_loss: 3.4723 - val_acc: 0.4967\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2234 - acc: 0.9210 - val_loss: 3.4961 - val_acc: 0.4920\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.2045 - acc: 0.9255 - val_loss: 3.4772 - val_acc: 0.4896\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2407 - acc: 0.9142 - val_loss: 3.4850 - val_acc: 0.4973\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2135 - acc: 0.9236 - val_loss: 3.5497 - val_acc: 0.4937\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2680 - acc: 0.9052 - val_loss: 3.6142 - val_acc: 0.4932\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2658 - acc: 0.9054 - val_loss: 3.6100 - val_acc: 0.4881\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2159 - acc: 0.9233 - val_loss: 3.5832 - val_acc: 0.4977\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2163 - acc: 0.9222 - val_loss: 3.5968 - val_acc: 0.4935\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1836 - acc: 0.9355 - val_loss: 3.6810 - val_acc: 0.4964\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2326 - acc: 0.9167 - val_loss: 3.5458 - val_acc: 0.4950\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2459 - acc: 0.9123 - val_loss: 3.5850 - val_acc: 0.4943\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2308 - acc: 0.9173 - val_loss: 3.7596 - val_acc: 0.4888\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.1856 - acc: 0.9343 - val_loss: 3.7268 - val_acc: 0.4941\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2206 - acc: 0.9213 - val_loss: 3.7293 - val_acc: 0.4939\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1832 - acc: 0.9347 - val_loss: 3.6987 - val_acc: 0.4971\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1659 - acc: 0.9400 - val_loss: 3.8489 - val_acc: 0.4929\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2669 - acc: 0.9061 - val_loss: 3.7331 - val_acc: 0.4948\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2151 - acc: 0.9229 - val_loss: 3.7880 - val_acc: 0.4922\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2184 - acc: 0.9222 - val_loss: 3.7371 - val_acc: 0.4901\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.1959 - acc: 0.9299 - val_loss: 3.8199 - val_acc: 0.4971\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1918 - acc: 0.9317 - val_loss: 3.7432 - val_acc: 0.4996\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.1810 - acc: 0.9361 - val_loss: 3.8230 - val_acc: 0.4836\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1886 - acc: 0.9321 - val_loss: 3.8081 - val_acc: 0.4985\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.2273 - acc: 0.9192 - val_loss: 3.8080 - val_acc: 0.4953\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1749 - acc: 0.9367 - val_loss: 3.7759 - val_acc: 0.4933\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.2420 - acc: 0.9138 - val_loss: 3.8361 - val_acc: 0.4932\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1488 - acc: 0.9478 - val_loss: 3.8902 - val_acc: 0.4964\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.1556 - acc: 0.9443 - val_loss: 3.9431 - val_acc: 0.4952\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.2545 - acc: 0.9122 - val_loss: 3.9201 - val_acc: 0.4905\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2016 - acc: 0.9285 - val_loss: 3.8976 - val_acc: 0.4921\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.1768 - acc: 0.9378 - val_loss: 3.9114 - val_acc: 0.5034\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1694 - acc: 0.9403 - val_loss: 3.9312 - val_acc: 0.4977\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.1929 - acc: 0.9312 - val_loss: 3.8047 - val_acc: 0.4930\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2003 - acc: 0.9301 - val_loss: 3.9989 - val_acc: 0.4902\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.2077 - acc: 0.9271 - val_loss: 3.9837 - val_acc: 0.4946\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2072 - acc: 0.9275 - val_loss: 4.0287 - val_acc: 0.4923\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.1493 - acc: 0.9467 - val_loss: 3.9757 - val_acc: 0.4951\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.1551 - acc: 0.9449 - val_loss: 4.1336 - val_acc: 0.4944\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.1747 - acc: 0.9390 - val_loss: 4.0463 - val_acc: 0.4842\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2008 - acc: 0.9286 - val_loss: 4.1276 - val_acc: 0.4893\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.2064 - acc: 0.9270 - val_loss: 4.0425 - val_acc: 0.4945\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.1758 - acc: 0.9382 - val_loss: 4.0896 - val_acc: 0.4912\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1720 - acc: 0.9385 - val_loss: 4.0015 - val_acc: 0.5015\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1565 - acc: 0.9442 - val_loss: 4.1276 - val_acc: 0.4927\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.1834 - acc: 0.9345 - val_loss: 4.1150 - val_acc: 0.4908\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.1944 - acc: 0.9317 - val_loss: 4.0745 - val_acc: 0.4890\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1826 - acc: 0.9357 - val_loss: 4.0414 - val_acc: 0.4939\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.1683 - acc: 0.9406 - val_loss: 4.1106 - val_acc: 0.4953\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1394 - acc: 0.9500 - val_loss: 4.1520 - val_acc: 0.4889\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.1536 - acc: 0.9436 - val_loss: 4.1466 - val_acc: 0.4963\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.1655 - acc: 0.9418 - val_loss: 4.2072 - val_acc: 0.4854\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.2120 - acc: 0.9270 - val_loss: 4.2548 - val_acc: 0.4903\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.2106 - acc: 0.9252 - val_loss: 4.1225 - val_acc: 0.4870\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1552 - acc: 0.9449 - val_loss: 4.1154 - val_acc: 0.4956: \n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.1314 - acc: 0.9542 - val_loss: 4.1490 - val_acc: 0.4949\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.1331 - acc: 0.9536 - val_loss: 4.2883 - val_acc: 0.4883\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1517 - acc: 0.9463 - val_loss: 4.2765 - val_acc: 0.4949\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.2107 - acc: 0.9283 - val_loss: 4.1551 - val_acc: 0.4946\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1801 - acc: 0.9377 - val_loss: 4.1646 - val_acc: 0.4950\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1671 - acc: 0.9412 - val_loss: 4.2097 - val_acc: 0.4987\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.1647 - acc: 0.9422 - val_loss: 4.1962 - val_acc: 0.4976\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1050 - acc: 0.9629 - val_loss: 4.2624 - val_acc: 0.4940\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1471 - acc: 0.9476 - val_loss: 4.3117 - val_acc: 0.4922\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.1736 - acc: 0.9390 - val_loss: 4.3280 - val_acc: 0.4973\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1888 - acc: 0.9357 - val_loss: 4.2123 - val_acc: 0.4897\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1520 - acc: 0.9461 - val_loss: 4.3033 - val_acc: 0.4937\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1587 - acc: 0.9431 - val_loss: 4.2497 - val_acc: 0.4993\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1818 - acc: 0.9364 - val_loss: 4.1674 - val_acc: 0.4983\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1452 - acc: 0.9487 - val_loss: 4.2924 - val_acc: 0.4969\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.1465 - acc: 0.9480 - val_loss: 4.2964 - val_acc: 0.4938\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0983 - acc: 0.9667 - val_loss: 4.2456 - val_acc: 0.4941\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.2311 - acc: 0.9216 - val_loss: 4.2411 - val_acc: 0.4917\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1377 - acc: 0.9525 - val_loss: 4.3891 - val_acc: 0.4855\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.1565 - acc: 0.9454 - val_loss: 4.3743 - val_acc: 0.4934\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.1213 - acc: 0.9578 - val_loss: 4.4159 - val_acc: 0.4890\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.1393 - acc: 0.9514 - val_loss: 4.4041 - val_acc: 0.4952\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.1597 - acc: 0.9452 - val_loss: 4.2984 - val_acc: 0.4938\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.2213 - acc: 0.9262 - val_loss: 4.2993 - val_acc: 0.4934\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1027 - acc: 0.9641 - val_loss: 4.3654 - val_acc: 0.4933\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0950 - acc: 0.9678 - val_loss: 4.4540 - val_acc: 0.4909\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1656 - acc: 0.9431 - val_loss: 4.4934 - val_acc: 0.4921\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.2057 - acc: 0.9308 - val_loss: 4.4685 - val_acc: 0.4797\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1264 - acc: 0.9563 - val_loss: 4.3631 - val_acc: 0.4986\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.0852 - acc: 0.9712 - val_loss: 4.4370 - val_acc: 0.4944\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.1213 - acc: 0.9572 - val_loss: 4.3870 - val_acc: 0.4957\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 0.1686 - acc: 0.9425 - val_loss: 4.4823 - val_acc: 0.4880\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2295 - acc: 0.9234 - val_loss: 4.5167 - val_acc: 0.4873\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1497 - acc: 0.9482 - val_loss: 4.4616 - val_acc: 0.4874\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.1059 - acc: 0.9624 - val_loss: 4.5424 - val_acc: 0.4972\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.0924 - acc: 0.9682 - val_loss: 4.4687 - val_acc: 0.4965\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.1451 - acc: 0.9507 - val_loss: 4.4916 - val_acc: 0.4995\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.1618 - acc: 0.9435 - val_loss: 4.5615 - val_acc: 0.4871\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.1521 - acc: 0.9479 - val_loss: 4.4612 - val_acc: 0.4943\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.1210 - acc: 0.9574 - val_loss: 4.4847 - val_acc: 0.4977\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 0.1962 - acc: 0.9342 - val_loss: 4.5554 - val_acc: 0.4956\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 11s 226us/step - loss: 0.1519 - acc: 0.9477 - val_loss: 4.4779 - val_acc: 0.4986\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.1129 - acc: 0.9604 - val_loss: 4.6015 - val_acc: 0.4925\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 0.1109 - acc: 0.9618 - val_loss: 4.5220 - val_acc: 0.4971\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.1760 - acc: 0.9407 - val_loss: 4.5186 - val_acc: 0.4920\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1262 - acc: 0.9552 - val_loss: 4.4584 - val_acc: 0.4980\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 10s 205us/step - loss: 0.1180 - acc: 0.9590 - val_loss: 4.6189 - val_acc: 0.4934\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.1189 - acc: 0.9587 - val_loss: 4.5117 - val_acc: 0.4923\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1654 - acc: 0.9439 - val_loss: 4.4941 - val_acc: 0.5010\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.1249 - acc: 0.9568 - val_loss: 4.5307 - val_acc: 0.4971\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.1053 - acc: 0.9628 - val_loss: 4.5849 - val_acc: 0.5040\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.1549 - acc: 0.9465 - val_loss: 4.5842 - val_acc: 0.4905\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.1645 - acc: 0.9443 - val_loss: 4.5702 - val_acc: 0.4931\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.1280 - acc: 0.9555 - val_loss: 4.5137 - val_acc: 0.4931\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 0.0930 - acc: 0.9671 - val_loss: 4.5455 - val_acc: 0.4997\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 0.0922 - acc: 0.9682 - val_loss: 4.6659 - val_acc: 0.4905\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 0.2610 - acc: 0.9185 - val_loss: 4.5987 - val_acc: 0.4895\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 0.1780 - acc: 0.9398 - val_loss: 4.6756 - val_acc: 0.4935\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0776 - acc: 0.9732 - val_loss: 4.6315 - val_acc: 0.4957\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0662 - acc: 0.9769 - val_loss: 4.6701 - val_acc: 0.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0590 - acc: 0.9799 - val_loss: 4.7192 - val_acc: 0.4952\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.1308 - acc: 0.9563 - val_loss: 4.6696 - val_acc: 0.4978\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.2998 - acc: 0.9089 - val_loss: 4.6320 - val_acc: 0.4924\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1288 - acc: 0.9556 - val_loss: 4.5936 - val_acc: 0.4936\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.0760 - acc: 0.9739 - val_loss: 4.6941 - val_acc: 0.4934\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0651 - acc: 0.9781 - val_loss: 4.7106 - val_acc: 0.4978\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.0842 - acc: 0.9709 - val_loss: 4.6346 - val_acc: 0.4982\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1581 - acc: 0.9468 - val_loss: 4.6578 - val_acc: 0.4831\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1894 - acc: 0.9385 - val_loss: 4.5843 - val_acc: 0.4922\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.1698 - acc: 0.9421 - val_loss: 4.6186 - val_acc: 0.4930\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.0847 - acc: 0.9706 - val_loss: 4.6295 - val_acc: 0.4942\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.1183 - acc: 0.9586 - val_loss: 4.7162 - val_acc: 0.4934\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1027 - acc: 0.9645 - val_loss: 4.7462 - val_acc: 0.4890\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.1208 - acc: 0.9588 - val_loss: 4.6081 - val_acc: 0.4914\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.1213 - acc: 0.9576 - val_loss: 4.6337 - val_acc: 0.4980\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.1904 - acc: 0.9377 - val_loss: 4.7146 - val_acc: 0.4869\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.1471 - acc: 0.9509 - val_loss: 4.6481 - val_acc: 0.4958\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0993 - acc: 0.9645 - val_loss: 4.7732 - val_acc: 0.4889\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0784 - acc: 0.9723 - val_loss: 4.6561 - val_acc: 0.4933\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0813 - acc: 0.9724 - val_loss: 4.7651 - val_acc: 0.4949\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1603 - acc: 0.9470 - val_loss: 4.8057 - val_acc: 0.4863\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.2391 - acc: 0.9241 - val_loss: 4.7016 - val_acc: 0.4876\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0986 - acc: 0.9652 - val_loss: 4.5928 - val_acc: 0.5031\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0746 - acc: 0.9741 - val_loss: 4.7191 - val_acc: 0.4938: 1s - loss: 0.0773\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0890 - acc: 0.9700 - val_loss: 4.6671 - val_acc: 0.4947s - loss: 0.0811 - ETA: \n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0991 - acc: 0.9658 - val_loss: 4.7285 - val_acc: 0.4891\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0912 - acc: 0.9692 - val_loss: 4.7400 - val_acc: 0.4885\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1876 - acc: 0.9397 - val_loss: 4.8912 - val_acc: 0.4895loss: 0.1810 \n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1443 - acc: 0.9513 - val_loss: 4.6789 - val_acc: 0.4967\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0964 - acc: 0.9668 - val_loss: 4.7699 - val_acc: 0.4930\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1050 - acc: 0.9637 - val_loss: 4.7763 - val_acc: 0.4915\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1611 - acc: 0.9468 - val_loss: 4.7984 - val_acc: 0.4900\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1154 - acc: 0.9604 - val_loss: 4.7751 - val_acc: 0.4948\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1041 - acc: 0.9653 - val_loss: 4.7643 - val_acc: 0.4944\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1398 - acc: 0.9527 - val_loss: 4.8046 - val_acc: 0.4921\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0894 - acc: 0.9696 - val_loss: 4.8483 - val_acc: 0.4878\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0959 - acc: 0.9660 - val_loss: 4.6997 - val_acc: 0.4934\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1057 - acc: 0.9635 - val_loss: 4.7671 - val_acc: 0.4969\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1027 - acc: 0.9651 - val_loss: 4.7831 - val_acc: 0.4899\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1087 - acc: 0.9631 - val_loss: 4.7968 - val_acc: 0.4851\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1466 - acc: 0.9517 - val_loss: 4.8574 - val_acc: 0.4914\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 0.1145 - acc: 0.9619 - val_loss: 4.9109 - val_acc: 0.4831\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1184 - acc: 0.9599 - val_loss: 4.8626 - val_acc: 0.4895\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0844 - acc: 0.9709 - val_loss: 4.8677 - val_acc: 0.4905\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1466 - acc: 0.9512 - val_loss: 4.7923 - val_acc: 0.4953oss: 0.1410 - acc: 0. - ETA: 1s - loss: 0.1424\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1706 - acc: 0.9443 - val_loss: 4.7214 - val_acc: 0.4971\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1679 - acc: 0.9451 - val_loss: 4.7718 - val_acc: 0.4953\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0745 - acc: 0.9744 - val_loss: 4.7645 - val_acc: 0.5014\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 4.8219 - val_acc: 0.5026.0370 -\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 4.9328 - val_acc: 0.5022\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1346 - acc: 0.9569 - val_loss: 4.9231 - val_acc: 0.4812\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.2872 - acc: 0.9143 - val_loss: 4.7986 - val_acc: 0.4926\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1219 - acc: 0.9594 - val_loss: 4.8068 - val_acc: 0.4918\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.0531 - acc: 0.9826 - val_loss: 4.8004 - val_acc: 0.4903\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0463 - acc: 0.9840 - val_loss: 4.8767 - val_acc: 0.4959\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0734 - acc: 0.9752 - val_loss: 4.9247 - val_acc: 0.4879\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1708 - acc: 0.9449 - val_loss: 4.8961 - val_acc: 0.4968\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.1374 - acc: 0.9532 - val_loss: 4.8458 - val_acc: 0.4878\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1236 - acc: 0.9581 - val_loss: 4.8317 - val_acc: 0.4902\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0839 - acc: 0.9711 - val_loss: 4.8899 - val_acc: 0.4946\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0676 - acc: 0.9771 - val_loss: 4.9043 - val_acc: 0.4935\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0667 - acc: 0.9763 - val_loss: 4.9362 - val_acc: 0.4927\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 0.1292 - acc: 0.9579 - val_loss: 4.9137 - val_acc: 0.4861\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 11s 223us/step - loss: 0.2851 - acc: 0.9157 - val_loss: 4.7539 - val_acc: 0.4932\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.0998 - acc: 0.9668 - val_loss: 4.7712 - val_acc: 0.4950\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0537 - acc: 0.9811 - val_loss: 4.8405 - val_acc: 0.5017\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0253 - acc: 0.9926 - val_loss: 4.9280 - val_acc: 0.4933\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0210 - acc: 0.9943 - val_loss: 4.8768 - val_acc: 0.5068\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0525 - acc: 0.9822 - val_loss: 4.9134 - val_acc: 0.4931\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.2775 - acc: 0.9210 - val_loss: 4.8547 - val_acc: 0.4810\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1665 - acc: 0.9470 - val_loss: 4.8809 - val_acc: 0.4931\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1176 - acc: 0.9604 - val_loss: 4.8826 - val_acc: 0.4941\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.0782 - acc: 0.9728 - val_loss: 4.8974 - val_acc: 0.4932\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.0428 - acc: 0.9862 - val_loss: 4.8845 - val_acc: 0.4951\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0675 - acc: 0.9770 - val_loss: 4.9008 - val_acc: 0.4871\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1016 - acc: 0.9652 - val_loss: 4.9476 - val_acc: 0.4951TA: 1s - loss\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1562 - acc: 0.9497 - val_loss: 4.9325 - val_acc: 0.4927\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.1637 - acc: 0.9474 - val_loss: 4.9535 - val_acc: 0.4912\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1225 - acc: 0.9592 - val_loss: 4.8943 - val_acc: 0.4985\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.0590 - acc: 0.9803 - val_loss: 4.9063 - val_acc: 0.5019\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.0400 - acc: 0.9864 - val_loss: 4.9340 - val_acc: 0.4988\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0408 - acc: 0.9868 - val_loss: 4.9652 - val_acc: 0.4942\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.2094 - acc: 0.9373 - val_loss: 4.8377 - val_acc: 0.4850\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1819 - acc: 0.9437 - val_loss: 4.8629 - val_acc: 0.4907\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0831 - acc: 0.9713 - val_loss: 4.7529 - val_acc: 0.4993loss: 0.08\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.0490 - acc: 0.9836 - val_loss: 4.8852 - val_acc: 0.4965\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0746 - acc: 0.9748 - val_loss: 4.9158 - val_acc: 0.4949\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.1090 - acc: 0.9647 - val_loss: 4.9121 - val_acc: 0.4941\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1584 - acc: 0.9493 - val_loss: 4.9039 - val_acc: 0.4961\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1014 - acc: 0.9664 - val_loss: 4.9674 - val_acc: 0.4969\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.0622 - acc: 0.9788 - val_loss: 4.9398 - val_acc: 0.5021\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0527 - acc: 0.9825 - val_loss: 4.9732 - val_acc: 0.4985\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0560 - acc: 0.9819 - val_loss: 5.0159 - val_acc: 0.4937\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.1630 - acc: 0.9496 - val_loss: 4.9252 - val_acc: 0.4872\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.1970 - acc: 0.9390 - val_loss: 5.0635 - val_acc: 0.4928\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1212 - acc: 0.9596 - val_loss: 4.8416 - val_acc: 0.5001\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0449 - acc: 0.9851 - val_loss: 4.9457 - val_acc: 0.5017\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.0421 - acc: 0.9852 - val_loss: 4.9738 - val_acc: 0.4970\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.0561 - acc: 0.9805 - val_loss: 4.8956 - val_acc: 0.4979\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1142 - acc: 0.9615 - val_loss: 5.0880 - val_acc: 0.4948\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 0.2248 - acc: 0.9327 - val_loss: 5.0896 - val_acc: 0.4872\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1086 - acc: 0.9645 - val_loss: 4.9860 - val_acc: 0.4966\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 0.0432 - acc: 0.9854 - val_loss: 4.9472 - val_acc: 0.4973\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 0.0302 - acc: 0.9900 - val_loss: 5.0376 - val_acc: 0.5003\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0238 - acc: 0.9931 - val_loss: 5.0139 - val_acc: 0.4969\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1283 - acc: 0.9591 - val_loss: 5.0503 - val_acc: 0.4916\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 0.2381 - acc: 0.9306 - val_loss: 4.9800 - val_acc: 0.4916\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 0.0727 - acc: 0.9751 - val_loss: 5.0594 - val_acc: 0.4910\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 0.0608 - acc: 0.9802 - val_loss: 4.9919 - val_acc: 0.4946\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 10s 208us/step - loss: 0.0456 - acc: 0.9843 - val_loss: 4.9423 - val_acc: 0.4996\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0940 - acc: 0.9688 - val_loss: 5.0482 - val_acc: 0.4913\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.2114 - acc: 0.9359 - val_loss: 5.1184 - val_acc: 0.4796\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.1104 - acc: 0.9629 - val_loss: 4.9594 - val_acc: 0.4956\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0721 - acc: 0.9759 - val_loss: 5.0635 - val_acc: 0.4929\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0379 - acc: 0.9876 - val_loss: 4.9933 - val_acc: 0.4988\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0541 - acc: 0.9808 - val_loss: 5.0676 - val_acc: 0.4991.0541 - acc: 0.980\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0968 - acc: 0.9676 - val_loss: 5.1651 - val_acc: 0.4791\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.2087 - acc: 0.9366 - val_loss: 4.9278 - val_acc: 0.4932\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1106 - acc: 0.9638 - val_loss: 5.0822 - val_acc: 0.4830\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0862 - acc: 0.9705 - val_loss: 4.9579 - val_acc: 0.4974\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0444 - acc: 0.9853 - val_loss: 4.9945 - val_acc: 0.4959\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0442 - acc: 0.9855 - val_loss: 5.1076 - val_acc: 0.4938\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0922 - acc: 0.9696 - val_loss: 5.0213 - val_acc: 0.4869\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1167 - acc: 0.9620 - val_loss: 5.0452 - val_acc: 0.4942\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1349 - acc: 0.9560 - val_loss: 5.1159 - val_acc: 0.4853\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1055 - acc: 0.9653 - val_loss: 5.0239 - val_acc: 0.4969\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.0549 - acc: 0.9820 - val_loss: 5.1528 - val_acc: 0.4937\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0434 - acc: 0.9845 - val_loss: 5.0866 - val_acc: 0.49766\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0734 - acc: 0.9765 - val_loss: 5.1423 - val_acc: 0.4858\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2263 - acc: 0.9348 - val_loss: 5.0665 - val_acc: 0.4882\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0857 - acc: 0.9711 - val_loss: 5.0604 - val_acc: 0.4913\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0613 - acc: 0.9795 - val_loss: 5.0769 - val_acc: 0.4944\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0422 - acc: 0.9857 - val_loss: 5.1797 - val_acc: 0.4926\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0645 - acc: 0.9780 - val_loss: 5.2075 - val_acc: 0.4840\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1502 - acc: 0.9530 - val_loss: 5.1236 - val_acc: 0.4966\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1566 - acc: 0.9526 - val_loss: 5.1067 - val_acc: 0.4852\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0901 - acc: 0.9711 - val_loss: 4.9835 - val_acc: 0.4994\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0566 - acc: 0.9817 - val_loss: 5.1050 - val_acc: 0.4959\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0758 - acc: 0.9746 - val_loss: 5.2115 - val_acc: 0.4908\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1011 - acc: 0.9664 - val_loss: 5.0609 - val_acc: 0.4952\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1039 - acc: 0.9654 - val_loss: 5.1788 - val_acc: 0.4914\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0819 - acc: 0.9736 - val_loss: 5.1283 - val_acc: 0.4914\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0632 - acc: 0.9778 - val_loss: 5.2647 - val_acc: 0.4901\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0509 - acc: 0.9833 - val_loss: 5.1718 - val_acc: 0.4965\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1130 - acc: 0.9644 - val_loss: 5.1616 - val_acc: 0.4802\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.1496 - acc: 0.9527 - val_loss: 5.1343 - val_acc: 0.4923\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.1178 - acc: 0.9622 - val_loss: 5.0505 - val_acc: 0.4979\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0750 - acc: 0.9746 - val_loss: 5.1547 - val_acc: 0.4901\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0817 - acc: 0.9734 - val_loss: 5.1151 - val_acc: 0.4920\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0747 - acc: 0.9752 - val_loss: 5.2050 - val_acc: 0.4895\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1333 - acc: 0.9589 - val_loss: 5.1104 - val_acc: 0.4881\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0772 - acc: 0.9746 - val_loss: 5.0769 - val_acc: 0.4951\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0315 - acc: 0.9891 - val_loss: 5.0612 - val_acc: 0.4979\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0322 - acc: 0.9896 - val_loss: 5.1456 - val_acc: 0.4959- loss: 0.0297 - ETA: 0s - loss: 0.0300 -\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0962 - acc: 0.9696 - val_loss: 5.1843 - val_acc: 0.4893\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.2205 - acc: 0.9335 - val_loss: 5.3821 - val_acc: 0.4737\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.1071 - acc: 0.9665 - val_loss: 5.1214 - val_acc: 0.4922\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0636 - acc: 0.9793 - val_loss: 5.0416 - val_acc: 0.5017\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0219 - acc: 0.9937 - val_loss: 5.1873 - val_acc: 0.4942\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0091 - acc: 0.9981 - val_loss: 5.1334 - val_acc: 0.4998\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0061 - acc: 0.9990 - val_loss: 5.1462 - val_acc: 0.5009\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0049 - acc: 0.9995 - val_loss: 5.1703 - val_acc: 0.5027  - ETA: 3s - loss: 0.0048 - acc: 0 - E\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0051 - acc: 0.9993 - val_loss: 5.1940 - val_acc: 0.4992\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.2118 - acc: 0.9505 - val_loss: 5.3843 - val_acc: 0.4771\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.4516 - acc: 0.8864 - val_loss: 4.8869 - val_acc: 0.4943\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 10s 204us/step - loss: 0.1041 - acc: 0.9663 - val_loss: 4.9086 - val_acc: 0.4906\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0465 - acc: 0.9840 - val_loss: 5.0365 - val_acc: 0.4997\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.0234 - acc: 0.9926 - val_loss: 5.0172 - val_acc: 0.5015\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 0.0109 - acc: 0.9975 - val_loss: 5.0260 - val_acc: 0.5011\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0060 - acc: 0.9991 - val_loss: 5.0572 - val_acc: 0.4991\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0050 - acc: 0.9995 - val_loss: 5.0760 - val_acc: 0.5001\n",
      "Epoch 404/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0043 - acc: 0.9995 - val_loss: 5.0707 - val_acc: 0.5036\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 5.1141 - val_acc: 0.5052\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0029 - acc: 0.9998 - val_loss: 5.1270 - val_acc: 0.5033\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0039 - acc: 0.9996 - val_loss: 5.1391 - val_acc: 0.5014\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.6922 - acc: 0.8555 - val_loss: 4.6659 - val_acc: 0.4879\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 0.2339 - acc: 0.9295 - val_loss: 4.6712 - val_acc: 0.4897\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0562 - acc: 0.9816 - val_loss: 4.8075 - val_acc: 0.5000\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0235 - acc: 0.9941 - val_loss: 4.8655 - val_acc: 0.4986\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0136 - acc: 0.9973 - val_loss: 4.8558 - val_acc: 0.5044\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0091 - acc: 0.9987 - val_loss: 4.9413 - val_acc: 0.5018\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0102 - acc: 0.9980 - val_loss: 4.9113 - val_acc: 0.5059\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 4.9813 - val_acc: 0.5040\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0051 - acc: 0.9996 - val_loss: 4.9952 - val_acc: 0.5055\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 5.0288 - val_acc: 0.5054\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 5.0482 - val_acc: 0.5050\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 5.0862 - val_acc: 0.5037\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.6864 - acc: 0.8532 - val_loss: 4.6215 - val_acc: 0.4789\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2346 - acc: 0.9282 - val_loss: 4.5496 - val_acc: 0.4939\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0593 - acc: 0.9803 - val_loss: 4.6915 - val_acc: 0.4966cc\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0232 - acc: 0.9945 - val_loss: 4.7006 - val_acc: 0.5010\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.0201 - acc: 0.9950 - val_loss: 4.7711 - val_acc: 0.5044\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 0.0100 - acc: 0.9986 - val_loss: 4.8484 - val_acc: 0.5047\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0222 - acc: 0.9939 - val_loss: 4.9121 - val_acc: 0.4992\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2742 - acc: 0.9192 - val_loss: 4.7889 - val_acc: 0.4871\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.1214 - acc: 0.9608 - val_loss: 4.7982 - val_acc: 0.4927\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0422 - acc: 0.9860 - val_loss: 4.7885 - val_acc: 0.5000\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0207 - acc: 0.9948 - val_loss: 4.8946 - val_acc: 0.4974\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 0.0181 - acc: 0.9956 - val_loss: 4.8871 - val_acc: 0.5042\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0085 - acc: 0.9986 - val_loss: 4.9385 - val_acc: 0.4998\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.0071 - acc: 0.9991 - val_loss: 4.9694 - val_acc: 0.50171 - acc: 0.999\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0050 - acc: 0.9995 - val_loss: 4.9791 - val_acc: 0.5015\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.2673 - acc: 0.9390 - val_loss: 4.8953 - val_acc: 0.4742\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.4051 - acc: 0.8912 - val_loss: 4.5313 - val_acc: 0.4907\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0859 - acc: 0.9716 - val_loss: 4.5836 - val_acc: 0.5038\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0181 - acc: 0.9962 - val_loss: 4.7027 - val_acc: 0.5030\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0117 - acc: 0.9982 - val_loss: 4.7025 - val_acc: 0.5096\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0057 - acc: 0.9997 - val_loss: 4.7789 - val_acc: 0.5081\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.8047 - val_acc: 0.5094\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 4.8413 - val_acc: 0.5078\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 4.8450 - val_acc: 0.5064\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 4.9003 - val_acc: 0.5092\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0029 - acc: 0.9999 - val_loss: 4.8996 - val_acc: 0.5076\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 4.9389 - val_acc: 0.5063\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 4.9515 - val_acc: 0.5070\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0351 - acc: 0.9913 - val_loss: 5.2106 - val_acc: 0.4625\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.9030 - acc: 0.7948 - val_loss: 4.1444 - val_acc: 0.4911\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1473 - acc: 0.9496 - val_loss: 4.3987 - val_acc: 0.4863\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0549 - acc: 0.9815 - val_loss: 4.4800 - val_acc: 0.4999\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.0219 - acc: 0.9956 - val_loss: 4.5337 - val_acc: 0.5030\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0106 - acc: 0.9990 - val_loss: 4.6198 - val_acc: 0.5026\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.0061 - acc: 0.9998 - val_loss: 4.6808 - val_acc: 0.5040\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0050 - acc: 0.9999 - val_loss: 4.6963 - val_acc: 0.5052\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 4.7439 - val_acc: 0.5055\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 4.7866 - val_acc: 0.5057\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 4.8452 - val_acc: 0.5020\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 4.8551 - val_acc: 0.5034\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.4324 - acc: 0.8999 - val_loss: 4.3952 - val_acc: 0.4683\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.2546 - acc: 0.9213 - val_loss: 4.3516 - val_acc: 0.4952\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0576 - acc: 0.9811 - val_loss: 4.4972 - val_acc: 0.4948\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0364 - acc: 0.9888 - val_loss: 4.5513 - val_acc: 0.5019\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0237 - acc: 0.9936 - val_loss: 4.6558 - val_acc: 0.4999\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0122 - acc: 0.9979 - val_loss: 4.6830 - val_acc: 0.5009loss: 0\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0076 - acc: 0.9993 - val_loss: 4.6975 - val_acc: 0.5078\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0045 - acc: 0.9998 - val_loss: 4.7507 - val_acc: 0.5044\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0035 - acc: 0.9999 - val_loss: 4.8040 - val_acc: 0.5066\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.3150 - acc: 0.9198 - val_loss: 4.5351 - val_acc: 0.4777\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2311 - acc: 0.9274 - val_loss: 4.5536 - val_acc: 0.4871ETA: 4s - - ETA: 2s - loss: 0.2723 - - ETA: 1s - loss: 0.25\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0672 - acc: 0.9774 - val_loss: 4.5942 - val_acc: 0.4939\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0286 - acc: 0.9921 - val_loss: 4.6233 - val_acc: 0.4936\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.0130 - acc: 0.9975 - val_loss: 4.6883 - val_acc: 0.5030\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0161 - acc: 0.9967 - val_loss: 4.7654 - val_acc: 0.5021\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0718 - acc: 0.9767 - val_loss: 4.8832 - val_acc: 0.4807\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.2320 - acc: 0.9287 - val_loss: 4.7846 - val_acc: 0.4967\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0990 - acc: 0.9668 - val_loss: 4.7510 - val_acc: 0.48828 -\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 0.0339 - acc: 0.9899 - val_loss: 4.7516 - val_acc: 0.5035\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 0.0179 - acc: 0.9952 - val_loss: 4.8268 - val_acc: 0.4985\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0070 - acc: 0.9991 - val_loss: 4.8421 - val_acc: 0.5016\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0067 - acc: 0.9992 - val_loss: 4.8524 - val_acc: 0.5005\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0035 - acc: 0.9998 - val_loss: 4.8867 - val_acc: 0.5047\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0025 - acc: 0.9999 - val_loss: 4.9045 - val_acc: 0.5041\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 4.9510 - val_acc: 0.5059\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 4.9806 - val_acc: 0.5029\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 4.9937 - val_acc: 0.5046\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 5.0275 - val_acc: 0.5043\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.0465 - val_acc: 0.5052\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.5178 - acc: 0.9027 - val_loss: 4.2041 - val_acc: 0.4518\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.4625 - acc: 0.8707 - val_loss: 4.2476 - val_acc: 0.4846\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 10s 191us/step - loss: 0.0825 - acc: 0.9742 - val_loss: 4.3877 - val_acc: 0.5023\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0233 - acc: 0.9952 - val_loss: 4.4660 - val_acc: 0.5039\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.0114 - acc: 0.9987 - val_loss: 4.5003 - val_acc: 0.5047\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 10s 190us/step - loss: 0.0067 - acc: 0.9997 - val_loss: 4.5683 - val_acc: 0.5016\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.0049 - acc: 0.9999 - val_loss: 4.6362 - val_acc: 0.5069\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 10s 192us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.6970 - val_acc: 0.5045\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 4.7133 - val_acc: 0.5051\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 9s 189us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 4.7379 - val_acc: 0.5052\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 4.8168 - val_acc: 0.5036\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 4.8213 - val_acc: 0.5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f02b04d978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer 換成 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n",
    "model = build_mlp()\n",
    "# 用 Keras 內建方法檢視模型各層參數量\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.2602 - acc: 0.1634 - val_loss: 2.2119 - val_acc: 0.2173\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 2.1792 - acc: 0.2333 - val_loss: 2.1458 - val_acc: 0.2480\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 2.1202 - acc: 0.2590 - val_loss: 2.0954 - val_acc: 0.2624\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.0745 - acc: 0.2745 - val_loss: 2.0549 - val_acc: 0.2757\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.0381 - acc: 0.2849 - val_loss: 2.0232 - val_acc: 0.2865\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 2.0086 - acc: 0.2946 - val_loss: 1.9973 - val_acc: 0.2972\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.9839 - acc: 0.3046 - val_loss: 1.9749 - val_acc: 0.3049\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.9630 - acc: 0.3130 - val_loss: 1.9554 - val_acc: 0.3131\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.9447 - acc: 0.3206 - val_loss: 1.9400 - val_acc: 0.3165\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.9288 - acc: 0.3285 - val_loss: 1.9251 - val_acc: 0.3200\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.9145 - acc: 0.3343 - val_loss: 1.9116 - val_acc: 0.3303\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.9015 - acc: 0.3401 - val_loss: 1.8993 - val_acc: 0.3374\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8897 - acc: 0.3441 - val_loss: 1.8885 - val_acc: 0.3393\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8791 - acc: 0.3486 - val_loss: 1.8782 - val_acc: 0.3482\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8689 - acc: 0.3532 - val_loss: 1.8676 - val_acc: 0.3521\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8599 - acc: 0.3548 - val_loss: 1.8595 - val_acc: 0.3573\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8514 - acc: 0.3593 - val_loss: 1.8514 - val_acc: 0.3571\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8433 - acc: 0.3627 - val_loss: 1.8434 - val_acc: 0.3664\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8357 - acc: 0.3647 - val_loss: 1.8365 - val_acc: 0.3668\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8285 - acc: 0.3678 - val_loss: 1.8301 - val_acc: 0.3705\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8218 - acc: 0.3697 - val_loss: 1.8241 - val_acc: 0.3695\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8153 - acc: 0.3734 - val_loss: 1.8167 - val_acc: 0.3726\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8088 - acc: 0.3735 - val_loss: 1.8105 - val_acc: 0.3750\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8028 - acc: 0.3769 - val_loss: 1.8056 - val_acc: 0.3759\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7969 - acc: 0.3783 - val_loss: 1.7996 - val_acc: 0.3814\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7908 - acc: 0.3813 - val_loss: 1.7940 - val_acc: 0.3794\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7850 - acc: 0.3822 - val_loss: 1.7887 - val_acc: 0.3806\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7796 - acc: 0.3851 - val_loss: 1.7831 - val_acc: 0.3853\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7742 - acc: 0.3864 - val_loss: 1.7779 - val_acc: 0.3847\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7689 - acc: 0.3881 - val_loss: 1.7733 - val_acc: 0.3882\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7637 - acc: 0.3895 - val_loss: 1.7689 - val_acc: 0.3892\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7588 - acc: 0.3913 - val_loss: 1.7636 - val_acc: 0.3901\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.7541 - acc: 0.3934 - val_loss: 1.7593 - val_acc: 0.3944\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7493 - acc: 0.3943 - val_loss: 1.7531 - val_acc: 0.3961\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7445 - acc: 0.3967 - val_loss: 1.7495 - val_acc: 0.3956\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7400 - acc: 0.3967 - val_loss: 1.7457 - val_acc: 0.3963\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7357 - acc: 0.3995 - val_loss: 1.7404 - val_acc: 0.3982\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7309 - acc: 0.4009 - val_loss: 1.7353 - val_acc: 0.3986\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7266 - acc: 0.4017 - val_loss: 1.7322 - val_acc: 0.4002\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7224 - acc: 0.4037 - val_loss: 1.7288 - val_acc: 0.4020\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7185 - acc: 0.4050 - val_loss: 1.7242 - val_acc: 0.4017\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7143 - acc: 0.4059 - val_loss: 1.7205 - val_acc: 0.4026\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7104 - acc: 0.4083 - val_loss: 1.7199 - val_acc: 0.4014\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7064 - acc: 0.4090 - val_loss: 1.7122 - val_acc: 0.4040\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7026 - acc: 0.4100 - val_loss: 1.7096 - val_acc: 0.4083\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6989 - acc: 0.4120 - val_loss: 1.7052 - val_acc: 0.4087\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6950 - acc: 0.4119 - val_loss: 1.7009 - val_acc: 0.4079\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.6914 - acc: 0.4139 - val_loss: 1.6985 - val_acc: 0.4099\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6875 - acc: 0.4147 - val_loss: 1.6944 - val_acc: 0.4114\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6841 - acc: 0.4163 - val_loss: 1.6899 - val_acc: 0.4144\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6802 - acc: 0.4177 - val_loss: 1.6868 - val_acc: 0.4135\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6770 - acc: 0.4185 - val_loss: 1.6897 - val_acc: 0.4125\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6734 - acc: 0.4195 - val_loss: 1.6806 - val_acc: 0.4170\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6699 - acc: 0.4206 - val_loss: 1.6781 - val_acc: 0.4161\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6668 - acc: 0.4211 - val_loss: 1.6743 - val_acc: 0.4161\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6633 - acc: 0.4245 - val_loss: 1.6724 - val_acc: 0.4208\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6602 - acc: 0.4240 - val_loss: 1.6681 - val_acc: 0.4221\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6568 - acc: 0.4253 - val_loss: 1.6648 - val_acc: 0.4223\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6536 - acc: 0.4274 - val_loss: 1.6622 - val_acc: 0.4239\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6506 - acc: 0.4297 - val_loss: 1.6596 - val_acc: 0.4222\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.6471 - acc: 0.4292 - val_loss: 1.6559 - val_acc: 0.4280\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6443 - acc: 0.4291 - val_loss: 1.6530 - val_acc: 0.4255\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6413 - acc: 0.4316 - val_loss: 1.6516 - val_acc: 0.4254\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6381 - acc: 0.4324 - val_loss: 1.6499 - val_acc: 0.4287\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6354 - acc: 0.4331 - val_loss: 1.6471 - val_acc: 0.4273\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.6322 - acc: 0.4338 - val_loss: 1.6448 - val_acc: 0.4284\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.6293 - acc: 0.4359 - val_loss: 1.6409 - val_acc: 0.4337\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6263 - acc: 0.4359 - val_loss: 1.6382 - val_acc: 0.4280\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6236 - acc: 0.4359 - val_loss: 1.6342 - val_acc: 0.4292\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6209 - acc: 0.4367 - val_loss: 1.6345 - val_acc: 0.4283\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6181 - acc: 0.4379 - val_loss: 1.6299 - val_acc: 0.4339\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6156 - acc: 0.4402 - val_loss: 1.6281 - val_acc: 0.4324\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6126 - acc: 0.4406 - val_loss: 1.6249 - val_acc: 0.4356\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6100 - acc: 0.4406 - val_loss: 1.6237 - val_acc: 0.4326\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6072 - acc: 0.4409 - val_loss: 1.6210 - val_acc: 0.4352\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6049 - acc: 0.4431 - val_loss: 1.6187 - val_acc: 0.4353\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6020 - acc: 0.4436 - val_loss: 1.6157 - val_acc: 0.4382\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5995 - acc: 0.4443 - val_loss: 1.6127 - val_acc: 0.4387\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5969 - acc: 0.4462 - val_loss: 1.6119 - val_acc: 0.4368\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5945 - acc: 0.4468 - val_loss: 1.6119 - val_acc: 0.4389\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5919 - acc: 0.4478 - val_loss: 1.6062 - val_acc: 0.4391\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5893 - acc: 0.4477 - val_loss: 1.6056 - val_acc: 0.4400\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5871 - acc: 0.4488 - val_loss: 1.6035 - val_acc: 0.4403\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5845 - acc: 0.4504 - val_loss: 1.6015 - val_acc: 0.4431\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5822 - acc: 0.4501 - val_loss: 1.5995 - val_acc: 0.4444\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5800 - acc: 0.4525 - val_loss: 1.5962 - val_acc: 0.4409\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5774 - acc: 0.4520 - val_loss: 1.5948 - val_acc: 0.4430\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5754 - acc: 0.4528 - val_loss: 1.5914 - val_acc: 0.4456\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5730 - acc: 0.4549 - val_loss: 1.5899 - val_acc: 0.4452\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5711 - acc: 0.4548 - val_loss: 1.5916 - val_acc: 0.4415\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5688 - acc: 0.4559 - val_loss: 1.5875 - val_acc: 0.4455\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5667 - acc: 0.4566 - val_loss: 1.5848 - val_acc: 0.4468\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5643 - acc: 0.4578 - val_loss: 1.5825 - val_acc: 0.4466\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5624 - acc: 0.4582 - val_loss: 1.5830 - val_acc: 0.4448\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5601 - acc: 0.4589 - val_loss: 1.5786 - val_acc: 0.4479\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5579 - acc: 0.4591 - val_loss: 1.5770 - val_acc: 0.4485\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5561 - acc: 0.4606 - val_loss: 1.5793 - val_acc: 0.4450\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5540 - acc: 0.4583 - val_loss: 1.5744 - val_acc: 0.4493\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5519 - acc: 0.4615 - val_loss: 1.5733 - val_acc: 0.4486\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5498 - acc: 0.4625 - val_loss: 1.5709 - val_acc: 0.4509\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5476 - acc: 0.4639 - val_loss: 1.5748 - val_acc: 0.4439\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5462 - acc: 0.4627 - val_loss: 1.5683 - val_acc: 0.4522\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5438 - acc: 0.4642 - val_loss: 1.5660 - val_acc: 0.4514\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5421 - acc: 0.4658 - val_loss: 1.5640 - val_acc: 0.4513\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5399 - acc: 0.4664 - val_loss: 1.5693 - val_acc: 0.4494\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5380 - acc: 0.4665 - val_loss: 1.5631 - val_acc: 0.4522\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5359 - acc: 0.4675 - val_loss: 1.5590 - val_acc: 0.4550\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5345 - acc: 0.4669 - val_loss: 1.5569 - val_acc: 0.4537\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5322 - acc: 0.4691 - val_loss: 1.5561 - val_acc: 0.4551\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5305 - acc: 0.4686 - val_loss: 1.5557 - val_acc: 0.4547\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5284 - acc: 0.4691 - val_loss: 1.5566 - val_acc: 0.4548\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5266 - acc: 0.4700 - val_loss: 1.5523 - val_acc: 0.4539\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5246 - acc: 0.4708 - val_loss: 1.5504 - val_acc: 0.4567\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5232 - acc: 0.4721 - val_loss: 1.5485 - val_acc: 0.4554\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5211 - acc: 0.4719 - val_loss: 1.5504 - val_acc: 0.4567\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5191 - acc: 0.4730 - val_loss: 1.5465 - val_acc: 0.4564\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5173 - acc: 0.4728 - val_loss: 1.5457 - val_acc: 0.4587\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5154 - acc: 0.4743 - val_loss: 1.5439 - val_acc: 0.4560\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.5140 - acc: 0.4733 - val_loss: 1.5449 - val_acc: 0.4571\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5123 - acc: 0.4752 - val_loss: 1.5417 - val_acc: 0.4594\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5104 - acc: 0.4768 - val_loss: 1.5455 - val_acc: 0.4516\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5088 - acc: 0.4765 - val_loss: 1.5403 - val_acc: 0.4568\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5067 - acc: 0.4766 - val_loss: 1.5370 - val_acc: 0.4601\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5050 - acc: 0.4775 - val_loss: 1.5360 - val_acc: 0.4575\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5036 - acc: 0.4786 - val_loss: 1.5371 - val_acc: 0.4578\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5018 - acc: 0.4788 - val_loss: 1.5363 - val_acc: 0.4582\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4998 - acc: 0.4800 - val_loss: 1.5306 - val_acc: 0.4602\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4983 - acc: 0.4789 - val_loss: 1.5299 - val_acc: 0.4616\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4967 - acc: 0.4809 - val_loss: 1.5306 - val_acc: 0.4619\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4945 - acc: 0.4817 - val_loss: 1.5281 - val_acc: 0.4609\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4932 - acc: 0.4818 - val_loss: 1.5254 - val_acc: 0.4622\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4916 - acc: 0.4823 - val_loss: 1.5241 - val_acc: 0.4652\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4899 - acc: 0.4824 - val_loss: 1.5267 - val_acc: 0.4627\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4883 - acc: 0.4834 - val_loss: 1.5233 - val_acc: 0.4630\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4862 - acc: 0.4843 - val_loss: 1.5201 - val_acc: 0.4619\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4845 - acc: 0.4847 - val_loss: 1.5298 - val_acc: 0.4614\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4832 - acc: 0.4849 - val_loss: 1.5195 - val_acc: 0.4698\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4813 - acc: 0.4847 - val_loss: 1.5176 - val_acc: 0.4650\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4794 - acc: 0.4862 - val_loss: 1.5203 - val_acc: 0.4652\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4781 - acc: 0.4863 - val_loss: 1.5185 - val_acc: 0.4639\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.4763 - acc: 0.4879 - val_loss: 1.5174 - val_acc: 0.4677\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4748 - acc: 0.4880 - val_loss: 1.5175 - val_acc: 0.4612\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.4733 - acc: 0.4878 - val_loss: 1.5135 - val_acc: 0.4707\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4716 - acc: 0.4891 - val_loss: 1.5123 - val_acc: 0.4706\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4699 - acc: 0.4893 - val_loss: 1.5121 - val_acc: 0.4632\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4684 - acc: 0.4904 - val_loss: 1.5119 - val_acc: 0.4658\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4668 - acc: 0.4904 - val_loss: 1.5070 - val_acc: 0.4720\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4651 - acc: 0.4910 - val_loss: 1.5109 - val_acc: 0.4673\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4633 - acc: 0.4926 - val_loss: 1.5071 - val_acc: 0.4696\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4618 - acc: 0.4928 - val_loss: 1.5094 - val_acc: 0.4660\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4602 - acc: 0.4934 - val_loss: 1.5026 - val_acc: 0.4672\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4586 - acc: 0.4942 - val_loss: 1.5037 - val_acc: 0.4719\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4572 - acc: 0.4936 - val_loss: 1.5095 - val_acc: 0.4702\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.4557 - acc: 0.4948 - val_loss: 1.4981 - val_acc: 0.4700\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4538 - acc: 0.4953 - val_loss: 1.5016 - val_acc: 0.4694\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4523 - acc: 0.4961 - val_loss: 1.5052 - val_acc: 0.4681\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4506 - acc: 0.4958 - val_loss: 1.5000 - val_acc: 0.4729\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.4491 - acc: 0.4974 - val_loss: 1.4990 - val_acc: 0.4750: 1.4555 - acc:  - ETA: 3s - loss: 1\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4475 - acc: 0.4979 - val_loss: 1.4959 - val_acc: 0.4736\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4459 - acc: 0.4984 - val_loss: 1.4933 - val_acc: 0.4754\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4443 - acc: 0.4975 - val_loss: 1.4932 - val_acc: 0.4743\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.4427 - acc: 0.4991 - val_loss: 1.4935 - val_acc: 0.4752\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4414 - acc: 0.4984 - val_loss: 1.4884 - val_acc: 0.4766\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4397 - acc: 0.5006 - val_loss: 1.4889 - val_acc: 0.4799\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.4379 - acc: 0.5008 - val_loss: 1.4890 - val_acc: 0.4782\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4368 - acc: 0.5005 - val_loss: 1.4898 - val_acc: 0.4754\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4351 - acc: 0.5016 - val_loss: 1.4895 - val_acc: 0.4722\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4335 - acc: 0.5027 - val_loss: 1.4868 - val_acc: 0.4728\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4321 - acc: 0.5035 - val_loss: 1.4815 - val_acc: 0.4815\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.4305 - acc: 0.5025 - val_loss: 1.4826 - val_acc: 0.4787\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4290 - acc: 0.5037 - val_loss: 1.4858 - val_acc: 0.4769\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4275 - acc: 0.5051 - val_loss: 1.4835 - val_acc: 0.4805\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.4257 - acc: 0.5049 - val_loss: 1.4822 - val_acc: 0.4749 loss: 1.4244 -\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4247 - acc: 0.5054 - val_loss: 1.4783 - val_acc: 0.4801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4227 - acc: 0.5059 - val_loss: 1.4768 - val_acc: 0.4785\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4213 - acc: 0.5063 - val_loss: 1.4803 - val_acc: 0.4733\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4202 - acc: 0.5060 - val_loss: 1.4810 - val_acc: 0.4774\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4185 - acc: 0.5075 - val_loss: 1.4762 - val_acc: 0.4748\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4167 - acc: 0.5083 - val_loss: 1.4778 - val_acc: 0.4798\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.4159 - acc: 0.5081 - val_loss: 1.4749 - val_acc: 0.4804\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4137 - acc: 0.5095 - val_loss: 1.4727 - val_acc: 0.4854\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.4121 - acc: 0.5095 - val_loss: 1.4726 - val_acc: 0.4762\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4110 - acc: 0.5100 - val_loss: 1.4680 - val_acc: 0.4844\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.4092 - acc: 0.5109 - val_loss: 1.4752 - val_acc: 0.4781\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4080 - acc: 0.5125 - val_loss: 1.4681 - val_acc: 0.4841\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.4063 - acc: 0.5114 - val_loss: 1.4653 - val_acc: 0.4842\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4047 - acc: 0.5108 - val_loss: 1.4669 - val_acc: 0.4785\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4037 - acc: 0.5125 - val_loss: 1.4744 - val_acc: 0.4796\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4016 - acc: 0.5133 - val_loss: 1.4637 - val_acc: 0.4801\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.4005 - acc: 0.5129 - val_loss: 1.4668 - val_acc: 0.4837\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3990 - acc: 0.5140 - val_loss: 1.4648 - val_acc: 0.4837\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3972 - acc: 0.5143 - val_loss: 1.4596 - val_acc: 0.4847\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3962 - acc: 0.5142 - val_loss: 1.4594 - val_acc: 0.4882\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3943 - acc: 0.5160 - val_loss: 1.4650 - val_acc: 0.4807\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.3937 - acc: 0.5160 - val_loss: 1.4597 - val_acc: 0.4851\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 2461s 49ms/step - loss: 1.3916 - acc: 0.5166 - val_loss: 1.4588 - val_acc: 0.4843\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.3905 - acc: 0.5165 - val_loss: 1.4588 - val_acc: 0.4843\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3888 - acc: 0.5181 - val_loss: 1.4544 - val_acc: 0.4881\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.3874 - acc: 0.5184 - val_loss: 1.4523 - val_acc: 0.4853\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3858 - acc: 0.5192 - val_loss: 1.4666 - val_acc: 0.4828 loss: 1.3\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.3845 - acc: 0.5192 - val_loss: 1.4502 - val_acc: 0.4871\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3828 - acc: 0.5183 - val_loss: 1.4510 - val_acc: 0.4857\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3822 - acc: 0.5197 - val_loss: 1.4563 - val_acc: 0.4869\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.3803 - acc: 0.5202 - val_loss: 1.4675 - val_acc: 0.4801\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3787 - acc: 0.5225 - val_loss: 1.4537 - val_acc: 0.4828\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.3775 - acc: 0.5217 - val_loss: 1.4541 - val_acc: 0.4845\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3764 - acc: 0.5219 - val_loss: 1.4525 - val_acc: 0.4887\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.3745 - acc: 0.5226 - val_loss: 1.4462 - val_acc: 0.4896\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3733 - acc: 0.5219 - val_loss: 1.4549 - val_acc: 0.4865\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3716 - acc: 0.5232 - val_loss: 1.4615 - val_acc: 0.4853\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3705 - acc: 0.5233 - val_loss: 1.4424 - val_acc: 0.4880\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3686 - acc: 0.5251 - val_loss: 1.4461 - val_acc: 0.4846\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3676 - acc: 0.5246 - val_loss: 1.4475 - val_acc: 0.4843\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3659 - acc: 0.5256 - val_loss: 1.4502 - val_acc: 0.4867 0s - loss: 1.3672 - ac\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3647 - acc: 0.5266 - val_loss: 1.4381 - val_acc: 0.4929\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3632 - acc: 0.5263 - val_loss: 1.4540 - val_acc: 0.4782\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3619 - acc: 0.5259 - val_loss: 1.4489 - val_acc: 0.4833\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3601 - acc: 0.5298 - val_loss: 1.4399 - val_acc: 0.4907\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3588 - acc: 0.5272 - val_loss: 1.4408 - val_acc: 0.4883\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3577 - acc: 0.5280 - val_loss: 1.4421 - val_acc: 0.4879- loss: 1.3\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3560 - acc: 0.5292 - val_loss: 1.4392 - val_acc: 0.4865\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3551 - acc: 0.5295 - val_loss: 1.4363 - val_acc: 0.4898\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3532 - acc: 0.5298 - val_loss: 1.4448 - val_acc: 0.4830\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3524 - acc: 0.5309 - val_loss: 1.4344 - val_acc: 0.4916- acc: 0. - ETA: 1s - loss: \n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3508 - acc: 0.5310 - val_loss: 1.4327 - val_acc: 0.4881\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3495 - acc: 0.5316 - val_loss: 1.4424 - val_acc: 0.4830\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.3480 - acc: 0.5321 - val_loss: 1.4346 - val_acc: 0.4899\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3470 - acc: 0.5315 - val_loss: 1.4365 - val_acc: 0.4937\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3452 - acc: 0.5334 - val_loss: 1.4290 - val_acc: 0.4898\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3437 - acc: 0.5323 - val_loss: 1.4402 - val_acc: 0.4885\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3426 - acc: 0.5333 - val_loss: 1.4504 - val_acc: 0.4875\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.3413 - acc: 0.5343 - val_loss: 1.4264 - val_acc: 0.4931\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3401 - acc: 0.5345 - val_loss: 1.4328 - val_acc: 0.4918\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3383 - acc: 0.5351 - val_loss: 1.4256 - val_acc: 0.4968\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.3368 - acc: 0.5355 - val_loss: 1.4260 - val_acc: 0.4969\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3361 - acc: 0.5355 - val_loss: 1.4209 - val_acc: 0.4953\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.3343 - acc: 0.5364 - val_loss: 1.4294 - val_acc: 0.4931\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3332 - acc: 0.5362 - val_loss: 1.4328 - val_acc: 0.4900\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3320 - acc: 0.5355 - val_loss: 1.4217 - val_acc: 0.4959\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3305 - acc: 0.5382 - val_loss: 1.4196 - val_acc: 0.4945\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3291 - acc: 0.5384 - val_loss: 1.4174 - val_acc: 0.4975\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3277 - acc: 0.5383 - val_loss: 1.4190 - val_acc: 0.4943\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3265 - acc: 0.5387 - val_loss: 1.4183 - val_acc: 0.4943\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3249 - acc: 0.5399 - val_loss: 1.4286 - val_acc: 0.4954-  - ETA: 1s - loss: 1\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3236 - acc: 0.5399 - val_loss: 1.4291 - val_acc: 0.4900\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3228 - acc: 0.5393 - val_loss: 1.4312 - val_acc: 0.4917\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3212 - acc: 0.5405 - val_loss: 1.4200 - val_acc: 0.4951\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3201 - acc: 0.5409 - val_loss: 1.4223 - val_acc: 0.4955\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.3186 - acc: 0.5410 - val_loss: 1.4119 - val_acc: 0.4969\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.3175 - acc: 0.5413 - val_loss: 1.4211 - val_acc: 0.4963\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3160 - acc: 0.5423 - val_loss: 1.4156 - val_acc: 0.4976\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3146 - acc: 0.5431 - val_loss: 1.4179 - val_acc: 0.4986\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.3135 - acc: 0.5432 - val_loss: 1.4091 - val_acc: 0.5024\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3121 - acc: 0.5423 - val_loss: 1.4158 - val_acc: 0.4961\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3104 - acc: 0.5425 - val_loss: 1.4118 - val_acc: 0.4978\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3094 - acc: 0.5439 - val_loss: 1.4253 - val_acc: 0.4921\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3082 - acc: 0.5447 - val_loss: 1.4135 - val_acc: 0.4940\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.3073 - acc: 0.5455 - val_loss: 1.4060 - val_acc: 0.5032\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.3054 - acc: 0.5459 - val_loss: 1.4110 - val_acc: 0.4992\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.3045 - acc: 0.5452 - val_loss: 1.4073 - val_acc: 0.4988\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.3027 - acc: 0.5462 - val_loss: 1.4117 - val_acc: 0.4991\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.3016 - acc: 0.5465 - val_loss: 1.4040 - val_acc: 0.5024\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.3003 - acc: 0.5469 - val_loss: 1.4147 - val_acc: 0.5001\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2997 - acc: 0.5471 - val_loss: 1.4007 - val_acc: 0.5003\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2981 - acc: 0.5480 - val_loss: 1.4124 - val_acc: 0.4989\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2966 - acc: 0.5484 - val_loss: 1.3989 - val_acc: 0.5038\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2959 - acc: 0.5481 - val_loss: 1.4020 - val_acc: 0.5012\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2938 - acc: 0.5490 - val_loss: 1.4045 - val_acc: 0.5027\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2927 - acc: 0.5499 - val_loss: 1.4032 - val_acc: 0.5048\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2909 - acc: 0.5501 - val_loss: 1.4109 - val_acc: 0.5029\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2906 - acc: 0.5511 - val_loss: 1.4264 - val_acc: 0.4980\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2891 - acc: 0.5507 - val_loss: 1.3992 - val_acc: 0.5001\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2873 - acc: 0.5511 - val_loss: 1.3948 - val_acc: 0.5039\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2858 - acc: 0.5519 - val_loss: 1.4078 - val_acc: 0.4964\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2848 - acc: 0.5515 - val_loss: 1.4135 - val_acc: 0.4945\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2835 - acc: 0.5537 - val_loss: 1.3982 - val_acc: 0.5042\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2829 - acc: 0.5538 - val_loss: 1.3959 - val_acc: 0.5038\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2815 - acc: 0.5533 - val_loss: 1.3979 - val_acc: 0.5056\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2796 - acc: 0.5541 - val_loss: 1.4031 - val_acc: 0.5018\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2784 - acc: 0.5550 - val_loss: 1.3948 - val_acc: 0.5038\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2771 - acc: 0.5551 - val_loss: 1.4038 - val_acc: 0.5005\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2761 - acc: 0.5547 - val_loss: 1.3943 - val_acc: 0.5035\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2754 - acc: 0.5550 - val_loss: 1.3980 - val_acc: 0.4995\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2732 - acc: 0.5574 - val_loss: 1.4094 - val_acc: 0.5025\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.2727 - acc: 0.5571 - val_loss: 1.3993 - val_acc: 0.5043\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.2718 - acc: 0.5570 - val_loss: 1.4041 - val_acc: 0.5014\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2700 - acc: 0.5581 - val_loss: 1.4048 - val_acc: 0.5005\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2687 - acc: 0.5572 - val_loss: 1.3982 - val_acc: 0.5029\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2675 - acc: 0.5595 - val_loss: 1.3895 - val_acc: 0.5065\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.2660 - acc: 0.5589 - val_loss: 1.3993 - val_acc: 0.4995\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2658 - acc: 0.5596 - val_loss: 1.3929 - val_acc: 0.5036\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2639 - acc: 0.5594 - val_loss: 1.3948 - val_acc: 0.5009\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2625 - acc: 0.5600 - val_loss: 1.3916 - val_acc: 0.5026\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2618 - acc: 0.5613 - val_loss: 1.4070 - val_acc: 0.4997\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2600 - acc: 0.5611 - val_loss: 1.3914 - val_acc: 0.5068\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2596 - acc: 0.5608 - val_loss: 1.4040 - val_acc: 0.4980\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.2577 - acc: 0.5619 - val_loss: 1.3938 - val_acc: 0.5062\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.2563 - acc: 0.5611 - val_loss: 1.3917 - val_acc: 0.5052\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.2555 - acc: 0.5611 - val_loss: 1.4060 - val_acc: 0.4967\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.2548 - acc: 0.5619 - val_loss: 1.3923 - val_acc: 0.4984\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2528 - acc: 0.5638 - val_loss: 1.3819 - val_acc: 0.5069\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.2517 - acc: 0.5646 - val_loss: 1.3835 - val_acc: 0.5090\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2507 - acc: 0.5642 - val_loss: 1.3872 - val_acc: 0.5056\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2493 - acc: 0.5656 - val_loss: 1.3897 - val_acc: 0.5064oss: 1.24\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2482 - acc: 0.5648 - val_loss: 1.3855 - val_acc: 0.5062\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2470 - acc: 0.5655 - val_loss: 1.3859 - val_acc: 0.5056\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2458 - acc: 0.5660 - val_loss: 1.3914 - val_acc: 0.5027\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2449 - acc: 0.5668 - val_loss: 1.3880 - val_acc: 0.50532455 - acc: 0.56\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2439 - acc: 0.5665 - val_loss: 1.3778 - val_acc: 0.5094\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2413 - acc: 0.5693 - val_loss: 1.3921 - val_acc: 0.5031\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2410 - acc: 0.5676 - val_loss: 1.3822 - val_acc: 0.5082\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2396 - acc: 0.5692 - val_loss: 1.3864 - val_acc: 0.5094\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.2389 - acc: 0.5682 - val_loss: 1.3736 - val_acc: 0.5128\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.2379 - acc: 0.5683 - val_loss: 1.4022 - val_acc: 0.4940\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2357 - acc: 0.5697 - val_loss: 1.3969 - val_acc: 0.5066 3s - loss: 1.2225 -\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2342 - acc: 0.5701 - val_loss: 1.3783 - val_acc: 0.5100\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2336 - acc: 0.5713 - val_loss: 1.3795 - val_acc: 0.5050\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.2323 - acc: 0.5708 - val_loss: 1.3768 - val_acc: 0.5078\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.2313 - acc: 0.5713 - val_loss: 1.3961 - val_acc: 0.5061\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2301 - acc: 0.5719 - val_loss: 1.3782 - val_acc: 0.5064\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2289 - acc: 0.5725 - val_loss: 1.3707 - val_acc: 0.5115\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2277 - acc: 0.5728 - val_loss: 1.4003 - val_acc: 0.4974\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.2265 - acc: 0.5729 - val_loss: 1.4068 - val_acc: 0.4980\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.2256 - acc: 0.5722 - val_loss: 1.3758 - val_acc: 0.5130\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2251 - acc: 0.5732 - val_loss: 1.3801 - val_acc: 0.5084\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.2233 - acc: 0.5737 - val_loss: 1.3890 - val_acc: 0.5088\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2222 - acc: 0.5758 - val_loss: 1.3824 - val_acc: 0.5117\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2216 - acc: 0.5742 - val_loss: 1.3712 - val_acc: 0.5108\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2197 - acc: 0.5757 - val_loss: 1.3709 - val_acc: 0.5124\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2193 - acc: 0.5762 - val_loss: 1.3730 - val_acc: 0.5118\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2175 - acc: 0.5768 - val_loss: 1.3807 - val_acc: 0.5092\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.2167 - acc: 0.5767 - val_loss: 1.3820 - val_acc: 0.5133\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2157 - acc: 0.5774 - val_loss: 1.3748 - val_acc: 0.5094\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2139 - acc: 0.5765 - val_loss: 1.3713 - val_acc: 0.5110\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2133 - acc: 0.5787 - val_loss: 1.3675 - val_acc: 0.5141\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2116 - acc: 0.5775 - val_loss: 1.3726 - val_acc: 0.5106\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2113 - acc: 0.5782 - val_loss: 1.3891 - val_acc: 0.5099\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2103 - acc: 0.5780 - val_loss: 1.3720 - val_acc: 0.5154\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2084 - acc: 0.5802 - val_loss: 1.3873 - val_acc: 0.5122\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2076 - acc: 0.5808 - val_loss: 1.3810 - val_acc: 0.5121\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.2055 - acc: 0.5814 - val_loss: 1.3644 - val_acc: 0.5154\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2057 - acc: 0.5798 - val_loss: 1.3698 - val_acc: 0.5120\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2030 - acc: 0.5820 - val_loss: 1.3623 - val_acc: 0.5128\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.2030 - acc: 0.5832 - val_loss: 1.3638 - val_acc: 0.5138\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2007 - acc: 0.5821 - val_loss: 1.3659 - val_acc: 0.5135\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2001 - acc: 0.5824 - val_loss: 1.3683 - val_acc: 0.5149\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.1993 - acc: 0.5830 - val_loss: 1.3708 - val_acc: 0.5108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1981 - acc: 0.5824 - val_loss: 1.3955 - val_acc: 0.5082\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1978 - acc: 0.5845 - val_loss: 1.3603 - val_acc: 0.5183\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1953 - acc: 0.5847 - val_loss: 1.3591 - val_acc: 0.5165\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1940 - acc: 0.5839 - val_loss: 1.3590 - val_acc: 0.5179\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1941 - acc: 0.5856 - val_loss: 1.3695 - val_acc: 0.5125\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1922 - acc: 0.5863 - val_loss: 1.3677 - val_acc: 0.5148\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1918 - acc: 0.5863 - val_loss: 1.3682 - val_acc: 0.5104\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.1908 - acc: 0.5851 - val_loss: 1.3621 - val_acc: 0.5156\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1887 - acc: 0.5862 - val_loss: 1.3592 - val_acc: 0.5145\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1881 - acc: 0.5865 - val_loss: 1.3578 - val_acc: 0.5157\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1865 - acc: 0.5882 - val_loss: 1.3614 - val_acc: 0.5157\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1853 - acc: 0.5878 - val_loss: 1.3580 - val_acc: 0.5173\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1838 - acc: 0.5892 - val_loss: 1.3704 - val_acc: 0.5165\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1828 - acc: 0.5878 - val_loss: 1.3878 - val_acc: 0.5066\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.1830 - acc: 0.5899 - val_loss: 1.3818 - val_acc: 0.5085\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1810 - acc: 0.5895 - val_loss: 1.3738 - val_acc: 0.5151\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1806 - acc: 0.5888 - val_loss: 1.3669 - val_acc: 0.5146\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1790 - acc: 0.5899 - val_loss: 1.3583 - val_acc: 0.5204\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1780 - acc: 0.5900 - val_loss: 1.3798 - val_acc: 0.5127\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1771 - acc: 0.5919 - val_loss: 1.3579 - val_acc: 0.5158\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1755 - acc: 0.5913 - val_loss: 1.3589 - val_acc: 0.5160\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1747 - acc: 0.5924 - val_loss: 1.3863 - val_acc: 0.5050\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1739 - acc: 0.5911 - val_loss: 1.3789 - val_acc: 0.5131\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1725 - acc: 0.5924 - val_loss: 1.3658 - val_acc: 0.5160\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1707 - acc: 0.5928 - val_loss: 1.3560 - val_acc: 0.5173\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1695 - acc: 0.5945 - val_loss: 1.3617 - val_acc: 0.5143\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1686 - acc: 0.5934 - val_loss: 1.3512 - val_acc: 0.5196\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1685 - acc: 0.5951 - val_loss: 1.3933 - val_acc: 0.5053\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1674 - acc: 0.5952 - val_loss: 1.3608 - val_acc: 0.5174\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.1654 - acc: 0.5961 - val_loss: 1.3497 - val_acc: 0.5216\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1647 - acc: 0.5948 - val_loss: 1.3550 - val_acc: 0.5186\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1646 - acc: 0.5946 - val_loss: 1.3659 - val_acc: 0.5148\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1622 - acc: 0.5948 - val_loss: 1.3640 - val_acc: 0.5165\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1617 - acc: 0.5965 - val_loss: 1.3882 - val_acc: 0.5076\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1609 - acc: 0.5947 - val_loss: 1.3698 - val_acc: 0.5160\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1588 - acc: 0.5979 - val_loss: 1.3729 - val_acc: 0.5163\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1578 - acc: 0.5985 - val_loss: 1.4156 - val_acc: 0.5062\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.1570 - acc: 0.5981 - val_loss: 1.3645 - val_acc: 0.5177\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1570 - acc: 0.5964 - val_loss: 1.3737 - val_acc: 0.5167\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1564 - acc: 0.5983 - val_loss: 1.3489 - val_acc: 0.5235\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1533 - acc: 0.5997 - val_loss: 1.3876 - val_acc: 0.5104\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1523 - acc: 0.6008 - val_loss: 1.3574 - val_acc: 0.5184\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1508 - acc: 0.5993 - val_loss: 1.3531 - val_acc: 0.5204\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1506 - acc: 0.6009 - val_loss: 1.3489 - val_acc: 0.5216\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1490 - acc: 0.6015 - val_loss: 1.3728 - val_acc: 0.5108\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1492 - acc: 0.6007 - val_loss: 1.3670 - val_acc: 0.5111\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1463 - acc: 0.6017 - val_loss: 1.3517 - val_acc: 0.5203\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1463 - acc: 0.6019 - val_loss: 1.4024 - val_acc: 0.5057\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1443 - acc: 0.6029 - val_loss: 1.3568 - val_acc: 0.5194\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1432 - acc: 0.6034 - val_loss: 1.3613 - val_acc: 0.5163\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1416 - acc: 0.6059 - val_loss: 1.3495 - val_acc: 0.5229\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1418 - acc: 0.6054 - val_loss: 1.4218 - val_acc: 0.5012\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1417 - acc: 0.6049 - val_loss: 1.4753 - val_acc: 0.4883\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1405 - acc: 0.6050 - val_loss: 1.3558 - val_acc: 0.5179\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1377 - acc: 0.6068 - val_loss: 1.3422 - val_acc: 0.5246\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1380 - acc: 0.6040 - val_loss: 1.3827 - val_acc: 0.5147\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1378 - acc: 0.6043 - val_loss: 1.3498 - val_acc: 0.5213\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1341 - acc: 0.6066 - val_loss: 1.3511 - val_acc: 0.5221\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1336 - acc: 0.6068 - val_loss: 1.3441 - val_acc: 0.5213\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1328 - acc: 0.6079 - val_loss: 1.3776 - val_acc: 0.5145\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1314 - acc: 0.6068 - val_loss: 1.3486 - val_acc: 0.5197\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1307 - acc: 0.6089 - val_loss: 1.3777 - val_acc: 0.5069\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1310 - acc: 0.6070 - val_loss: 1.3738 - val_acc: 0.5143\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1292 - acc: 0.6088 - val_loss: 1.3722 - val_acc: 0.5149\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1287 - acc: 0.6077 - val_loss: 1.3599 - val_acc: 0.5166\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1268 - acc: 0.6085 - val_loss: 1.3673 - val_acc: 0.5157\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.1245 - acc: 0.6119 - val_loss: 1.3475 - val_acc: 0.5212\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1236 - acc: 0.6115 - val_loss: 1.3766 - val_acc: 0.5100\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1230 - acc: 0.6096 - val_loss: 1.3555 - val_acc: 0.5184\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1224 - acc: 0.6115 - val_loss: 1.3510 - val_acc: 0.5212\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1222 - acc: 0.6093 - val_loss: 1.3852 - val_acc: 0.5041\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1210 - acc: 0.6113 - val_loss: 1.3929 - val_acc: 0.5115\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1199 - acc: 0.6131 - val_loss: 1.3478 - val_acc: 0.5215\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1190 - acc: 0.6121 - val_loss: 1.3867 - val_acc: 0.5099\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1163 - acc: 0.6110 - val_loss: 1.3558 - val_acc: 0.5223\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.1158 - acc: 0.6138 - val_loss: 1.4040 - val_acc: 0.5003\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1142 - acc: 0.6136 - val_loss: 1.3455 - val_acc: 0.5226\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1141 - acc: 0.6144 - val_loss: 1.3528 - val_acc: 0.5205\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.1123 - acc: 0.6142 - val_loss: 1.4066 - val_acc: 0.5029\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1120 - acc: 0.6163 - val_loss: 1.3434 - val_acc: 0.5271\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.1115 - acc: 0.6137 - val_loss: 1.3466 - val_acc: 0.5232\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 1.1092 - acc: 0.6150 - val_loss: 1.3440 - val_acc: 0.5226\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.1093 - acc: 0.6166 - val_loss: 1.3429 - val_acc: 0.5276\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.1084 - acc: 0.6153 - val_loss: 1.3406 - val_acc: 0.5226\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.1057 - acc: 0.6166 - val_loss: 1.3807 - val_acc: 0.5062\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.1057 - acc: 0.6165 - val_loss: 1.3691 - val_acc: 0.5177\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.1069 - acc: 0.6158 - val_loss: 1.3459 - val_acc: 0.5219\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.1034 - acc: 0.6181 - val_loss: 1.3469 - val_acc: 0.5247\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.1036 - acc: 0.6168 - val_loss: 1.3705 - val_acc: 0.5153\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.1019 - acc: 0.6180 - val_loss: 1.3765 - val_acc: 0.5169\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.1000 - acc: 0.6183 - val_loss: 1.3478 - val_acc: 0.5263\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0987 - acc: 0.6181 - val_loss: 1.3395 - val_acc: 0.5265\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0981 - acc: 0.6198 - val_loss: 1.3627 - val_acc: 0.5246\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0964 - acc: 0.6202 - val_loss: 1.3545 - val_acc: 0.5224\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0954 - acc: 0.6203 - val_loss: 1.3461 - val_acc: 0.5239\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0938 - acc: 0.6217 - val_loss: 1.3428 - val_acc: 0.5243\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0924 - acc: 0.6215 - val_loss: 1.3694 - val_acc: 0.5204\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.0921 - acc: 0.6211 - val_loss: 1.3510 - val_acc: 0.5225\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.0911 - acc: 0.6217 - val_loss: 1.3606 - val_acc: 0.5124\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.0883 - acc: 0.6226 - val_loss: 1.3450 - val_acc: 0.5263\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.0911 - acc: 0.6222 - val_loss: 1.3483 - val_acc: 0.5266\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.0896 - acc: 0.6214 - val_loss: 1.3580 - val_acc: 0.5240\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 1.0876 - acc: 0.6227 - val_loss: 1.4061 - val_acc: 0.5077\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.0860 - acc: 0.6232 - val_loss: 1.3443 - val_acc: 0.5275\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.0868 - acc: 0.6230 - val_loss: 1.3554 - val_acc: 0.5182\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.0839 - acc: 0.6251 - val_loss: 1.3577 - val_acc: 0.5221\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0827 - acc: 0.6241 - val_loss: 1.3748 - val_acc: 0.5195\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0827 - acc: 0.6248 - val_loss: 1.3593 - val_acc: 0.5253\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0831 - acc: 0.6231 - val_loss: 1.3552 - val_acc: 0.5160\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.0809 - acc: 0.6269 - val_loss: 1.3436 - val_acc: 0.5263\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0794 - acc: 0.6264 - val_loss: 1.3449 - val_acc: 0.5237\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0777 - acc: 0.6262 - val_loss: 1.3655 - val_acc: 0.5178\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0778 - acc: 0.6257 - val_loss: 1.3728 - val_acc: 0.5166\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0792 - acc: 0.6261 - val_loss: 1.3495 - val_acc: 0.5258\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.0748 - acc: 0.6272 - val_loss: 1.3669 - val_acc: 0.5153\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0739 - acc: 0.6273 - val_loss: 1.3958 - val_acc: 0.5111\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0755 - acc: 0.6272 - val_loss: 1.3402 - val_acc: 0.5233\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.0743 - acc: 0.6276 - val_loss: 1.3799 - val_acc: 0.5136\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.0716 - acc: 0.6278 - val_loss: 1.3649 - val_acc: 0.5199\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.0706 - acc: 0.6292 - val_loss: 1.3476 - val_acc: 0.5183\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0688 - acc: 0.6292 - val_loss: 1.3567 - val_acc: 0.5252\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0692 - acc: 0.6279 - val_loss: 1.3436 - val_acc: 0.5270\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.0677 - acc: 0.6295 - val_loss: 1.3403 - val_acc: 0.5274\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.0668 - acc: 0.6289 - val_loss: 1.3879 - val_acc: 0.5102\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.0652 - acc: 0.6307 - val_loss: 1.3449 - val_acc: 0.5270\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0643 - acc: 0.6322 - val_loss: 1.3422 - val_acc: 0.5282\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0650 - acc: 0.6309 - val_loss: 1.3922 - val_acc: 0.5153\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0641 - acc: 0.6323 - val_loss: 1.3952 - val_acc: 0.5155\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0623 - acc: 0.6306 - val_loss: 1.3462 - val_acc: 0.5304\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.0597 - acc: 0.6319 - val_loss: 1.3432 - val_acc: 0.5249\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.0560 - acc: 0.6338 - val_loss: 1.3335 - val_acc: 0.5273\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.0598 - acc: 0.6318 - val_loss: 1.3461 - val_acc: 0.5244\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0575 - acc: 0.6331 - val_loss: 1.3357 - val_acc: 0.5274\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.0544 - acc: 0.6344 - val_loss: 1.3539 - val_acc: 0.5226\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.0573 - acc: 0.6338 - val_loss: 1.3413 - val_acc: 0.5228\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.0557 - acc: 0.6347 - val_loss: 1.3535 - val_acc: 0.5203\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.0543 - acc: 0.6346 - val_loss: 1.3423 - val_acc: 0.5307\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.0516 - acc: 0.6351 - val_loss: 1.3448 - val_acc: 0.5261\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.0522 - acc: 0.6361 - val_loss: 1.3504 - val_acc: 0.5295\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0515 - acc: 0.6359 - val_loss: 1.3620 - val_acc: 0.5233\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0495 - acc: 0.6362 - val_loss: 1.3421 - val_acc: 0.5252\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0489 - acc: 0.6350 - val_loss: 1.3732 - val_acc: 0.5173\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0459 - acc: 0.6380 - val_loss: 1.3430 - val_acc: 0.5264\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0457 - acc: 0.6382 - val_loss: 1.3666 - val_acc: 0.5200\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.0430 - acc: 0.6375 - val_loss: 1.3483 - val_acc: 0.5256\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0420 - acc: 0.6385 - val_loss: 1.3392 - val_acc: 0.5250\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.0469 - acc: 0.6379 - val_loss: 1.3337 - val_acc: 0.5289\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.0422 - acc: 0.6384 - val_loss: 1.3516 - val_acc: 0.5221\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.0419 - acc: 0.6397 - val_loss: 1.3522 - val_acc: 0.5229\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.0410 - acc: 0.6395 - val_loss: 1.3432 - val_acc: 0.5270\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.0406 - acc: 0.6389 - val_loss: 1.3649 - val_acc: 0.5172\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.0383 - acc: 0.6399 - val_loss: 1.3659 - val_acc: 0.5249\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.0375 - acc: 0.6404 - val_loss: 1.3680 - val_acc: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f048c82e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX6+PHPSS+kkQIhhdBbGhCaqIAgAioWLCjWte3q7lpWv6i7tvW3q7trW9u6FnRVxAJiQUBFKaJSQg+9BtILSUggfc7vjzMhIaSRDJnM5Hm/XvOamXvP3PvciM+cee655yqtNUIIIZyLi70DEEIIYXuS3IUQwglJchdCCCckyV0IIZyQJHchhHBCktyFEMIJSXIXQggnJMldOD2l1CGl1CR7xyFEe5LkLoQQTkiSu+i0lFJ3KKX2KaWOKqW+Ukr1sC5XSqkXlVI5SqkipdRWpVSsdd00pdQOpVSxUipdKfWgfY9CiIZJchedklLqAuAZ4BogHEgFPraungycD/QHAoFrgXzruneAu7TWfkAs8GM7hi1Ei7nZOwAh7GQWMEdrvRFAKfUIUKCUigEqAT9gILBOa72zzucqgcFKqS1a6wKgoF2jFqKFpOcuOqsemN46AFrrEkzvPEJr/SPwKvAakK2UelMp5W9tOgOYBqQqpVYqpca0c9xCtIgkd9FZZQA9a94opXyBYCAdQGv9stZ6ODAEU555yLp8vdb6MiAM+AL4tJ3jFqJFJLmLzsJdKeVV88Ak5VuVUolKKU/g78BarfUhpdQIpdQopZQ7cBwoA6qVUh5KqVlKqQCtdSVwDKi22xEJ0QRJ7qKzWAyU1nmcBzwGLAAygT7ATGtbf+AtTD09FVOuec667kbgkFLqGPBb4IZ2il+IM6LkZh1CCOF8pOcuhBBOSJK7EEI4IUnuQgjhhCS5CyGEE7LbFaohISE6JibGXrsXQgiHtGHDhjytdWhz7eyW3GNiYkhOTrbX7oUQwiEppVKbbyVlGSGEcEqS3IUQwglJchdCCCckU/4KIWyqsrKStLQ0ysrK7B2KQ/Py8iIyMhJ3d/dWfV6SuxDCptLS0vDz8yMmJgallL3DcUhaa/Lz80lLS6NXr16t2oaUZYQQNlVWVkZwcLAk9jZQShEcHNymXz+S3IUQNieJve3a+jd0uOS+O6uY57/bzdHjFfYORQghOiyHS+4Hckt45cd9ZB+TkzVCiNMVFhby+uuvt+qz06ZNo7CwsMXtn3zySZ577rnmG9qBwyV3H09zDvhERZWdIxFCdERNJffq6qZvnLV48WICAwPPRljtzuGSu6+HKwDHy+XuZkKI0z388MPs37+fxMREHnroIVasWMGECRO4/vrriYuLA+Dyyy9n+PDhDBkyhDfffPPkZ2NiYsjLy+PQoUMMGjSIO+64gyFDhjB58mRKS0ub3O/mzZsZPXo08fHxXHHFFRQUFADw8ssvM3jwYOLj45k509zsa+XKlSQmJpKYmMjQoUMpLi62+d/B4YZC+nhIz10IR/HU19vZkXHMptsc3MOfJy4d0uj6Z599lpSUFDZv3gzAihUrWLduHSkpKSeHFc6ZM4euXbtSWlrKiBEjmDFjBsHBwadsZ+/evcybN4+33nqLa665hgULFnDDDY3fVfGmm27ilVdeYdy4cTz++OM89dRTvPTSSzz77LMcPHgQT0/PkyWf5557jtdee42xY8dSUlKCl5dXW/8sp3G8nrun9NyFEGdm5MiRp4wXf/nll0lISGD06NEcOXKEvXv3nvaZXr16kZiYCMDw4cM5dOhQo9svKiqisLCQcePGAXDzzTezatUqAOLj45k1axYffvghbm6mczp27FgeeOABXn75ZQoLC08utyXpuQshzpqmetjtydfX9+TrFStWsGzZMn799Vd8fHwYP358g+PJPT09T752dXVttizTmG+++YZVq1bx1Vdf8fTTT7N9+3YefvhhLr74YhYvXszo0aNZtmwZAwcObNX2G+NwPXcfa839RIX03IUQp/Pz82uyhl1UVERQUBA+Pj7s2rWLNWvWtHmfAQEBBAUF8dNPPwHwwQcfMG7cOCwWC0eOHGHChAn885//pLCwkJKSEvbv309cXByzZ88mKSmJXbt2tTmG+ppN7kqpKKXUcqXUTqXUdqXUvQ20maWU2mp9/KKUSrB5pFbeGWt52/1fqOLMs7ULIYQDCw4OZuzYscTGxvLQQw+dtn7KlClUVVURHx/PY489xujRo22y3//973889NBDxMfHs3nzZh5//HGqq6u54YYbiIuLY+jQodx///0EBgby0ksvERsbS0JCAt7e3kydOtUmMdSltNZNN1AqHAjXWm9USvkBG4DLtdY76rQ5B9iptS5QSk0FntRaj2pqu0lJSbpVN+vYuQg+mcXbg97j9muvOPPPCyHOqp07dzJo0CB7h+EUGvpbKqU2aK2TmvtsszV3rXUmkGl9XayU2glEADvqtPmlzkfWAJEtC70VvPwBsJTb9gy8EEI4kzOquSulYoChwNommt0GLGnk83cqpZKVUsm5ublnsutann5mW5LchRCiUS1O7kqpLsAC4D6tdYOZVSk1AZPcZze0Xmv9ptY6SWudFBra7P1dG+Zpeu4u5bYf9C+EEM6iRUMhlVLumMQ+V2v9eSNt4oG3gala63zbhViPVwAArpWS3IUQojEtGS2jgHcwJ0xfaKRNNPA5cKPWeo9tQ6zHWpaR5C6EEI1rSc99LHAjsE0ptdm67FEgGkBr/QbwOBAMvG6dg7iqJWdzW8XNk0rljlvl8bOyeSGEcAbN9ty11qu11kprHa+1TrQ+Fmut37AmdrTWt2utg+qsPzuJ3arctQvuVdJzF0LYRpcuXQDIyMjgqquuarDN+PHjaWj4dmPL7c3hrlAFqHTzxbOqhObG6AshxJno0aMH8+fPt3cYNuGYyd3dD19KKa2UKQiEEKeaPXv2KfO5P/nkkzz//POUlJQwceJEhg0bRlxcHF9++eVpnz106BCxsbEAlJaWMnPmTOLj47n22mtbNLfMvHnziIuLIzY2ltmzzaDB6upqbrnlFmJjY4mLi+PFF18EGp4K2JYcbuIwAIuHP36qgKLSypMTiQkhOqAlD0PWNttus3scTH220dUzZ87kvvvu4+677wbg008/ZenSpXh5ebFw4UL8/f3Jy8tj9OjRTJ8+vdF7lf7nP//Bx8eHrVu3snXrVoYNG9ZkWBkZGcyePZsNGzYQFBTE5MmT+eKLL4iKiiI9PZ2UlBSAk9P+NjQVsC05ZM9dewYQyHGOlcrMkEKIUw0dOpScnBwyMjLYsmULQUFBREdHo7Xm0UcfJT4+nkmTJpGenk52dnaj21m1atXJ+dvj4+OJj49vcr/r169n/PjxhIaG4ubmxqxZs1i1ahW9e/fmwIED/OEPf2Dp0qX4+/uf3Gb9qYBtyTG7vT7BBKpiDpZW2jsSIURTmuhhn01XXXUV8+fPJysr62TJY+7cueTm5rJhwwbc3d2JiYlpcKrfuhrr1TeksXOAQUFBbNmyhW+//ZbXXnuNTz/9lDlz5jQ4FbAtk7xD9txdfLsSRAnHTlTYOxQhRAc0c+ZMPv74Y+bPn39y9EtRURFhYWG4u7uzfPlyUlNTm9zG+eefz9y5cwFISUlh69atTbYfNWoUK1euJC8vj+rqaubNm8e4cePIy8vDYrEwY8YMnn76aTZu3NjoVMC25JA9d/cuIbgpCyeKjwLd7R2OEKKDGTJkCMXFxURERBAeHg7ArFmzuPTSS0lKSiIxMbHZm2P87ne/49ZbbyU+Pp7ExERGjhzZZPvw8HCeeeYZJkyYgNaaadOmcdlll7FlyxZuvfVWLBYLAM8888zJqYCLiorQWp+cCtiWmp3y92xp9ZS/wIl1H+Cz+Pd8MuYrrr1onI0jE0K0hUz5azttmfLXIcsy3gEhAJQX59k5EiGE6JgcMrkrH3OX8qqSszc/mRBCODKHTO54dwXAIsldiA5Jrh5vu7b+DR0zufuasoxrmZRlhOhovLy8yM/PlwTfBlpr8vPz8fLyavU2HHK0DF4BVCp3vMoluQvR0URGRpKWlkar77YmAPMlGRnZ+juWOmZyV4oS92B8K47aOxIhRD3u7u706tXL3mF0eo5ZlgHKPUMIrC6gTCYPE0KI0zhscq/2CSNUFZJbXG7vUIQQosNx2OSu/LoRoorIOtb03BBCCNEZOWxydw8MJ5hicgrljkxCCFGfwyZ335BoXJSmJPeIvUMRQogOx2GTu3eoORtfmd/0zG5CCNEZOWxyV4FRAFQXHLZzJEII0fE4bHLHvwcALsfS7ByIEEJ0PI6b3N29KXbrim9pulzmLIQQ9TSb3JVSUUqp5UqpnUqp7Uqpextoo5RSLyul9imltiqlmr6TrI0c7xJDpCWDghNyuz0hhKirJT33KuBPWutBwGjgHqXU4HptpgL9rI87gf/YNMpGVHftSx+VwaH84+2xOyGEcBjNJnetdabWeqP1dTGwE4io1+wy4H1trAEClVLhNo+2Hs/uAwlWxWRlpJ/tXQkhhEM5o5q7UioGGAqsrbcqAqg74DyN078AUErdqZRKVkol22LGOP+oIQAUZ+xs87aEEMKZtDi5K6W6AAuA+7TWx+qvbuAjp53l1Fq/qbVO0lonhYaGnlmkDfDoNsC8yN3T5m0JIYQzaVFyV0q5YxL7XK315w00SQOi6ryPBDLaHl4zAqOpwB3Pov1nfVdCCOFIWjJaRgHvADu11i800uwr4CbrqJnRQJHWOtOGcTbMxZWjXtEEHj+IxSLDIYUQokZLbtYxFrgR2KaU2mxd9igQDaC1fgNYDEwD9gEngFttH2rDKoL60vvERlKPnqBXiG977VYIITq0ZpO71no1DdfU67bRwD22CupMeEQm0j3zW5YeOkKvkIH2CEEIITocx71C1Sq470gAju7fYOdIhBCi43D45O4emQiAS8ZGO0cihBAdh8Mnd3xDyPbsSWTRBpljRgghrBw/uQMF3cYwVO/gSG6RvUMRQogOwSmSu/+gC/BV5ezdvNLeoQghRIfgFMk9POFCLCgq9q6wdyhCCNEhOEVyVz5dSfPsS7f8dVJ3F0IInCS5AxSHn8OQ6l2k5Ry1dyhCCGF3TpPcg4ZMxFNVsXvdt/YORQgh7M5pknt4woWcwAvX3YvsHYoQQtid0yR35eHDwaBziS/+iZLScnuHI4QQduU0yR3APf5ygtUxUn5dYu9QhBDCrpwqufcefTmleFKxeb69QxFCCLtyquTu5u3Hvq7jiC/6kaPHSuwdjhBC2I1TJXeAwNE3EKiOs3HZJ/YORQgh7MbpknvU8IspUIF02fmxvUMRQgi7cbrkjqsbh3tfy+jKdezdts7e0QghhF04X3IHel38IMe1F8XfPWPvUIQQwi6cMrn7dw1jS/jVJB5bTub+rfYORwgh2p1TJneAvpfNphx3Mr+R3rsQovNx2uQeFh5FcshlxOcvJf9Qir3DEUKIduW0yR2g52V/4TjeFMz/A8hUwEKITsSpk3t0dAyre/6OviUbyVj9ob3DEUKIdtNscldKzVFK5SilGqxtKKUClFJfK6W2KKW2K6VutX2YrXfO1Q+yjT74LH8cXVpo73CEEKJdtKTn/h4wpYn19wA7tNYJwHjgeaWUR9tDs40gP2/2jXgav+oCjiz4s73DEUKIdtFsctdarwKaur2RBvyUUgroYm1bZZvwbOOSKVP52vNiIvZ9RGlqsr3DEUKIs84WNfdXgUFABrANuFdrbbHBdm3G3dWF6Kv+Rr72p+iT30FVhb1DEkKIs8oWyf0iYDPQA0gEXlVK+TfUUCl1p1IqWSmVnJuba4Ndt9yw/jEs7fkQ3U/sIWfRX9t130II0d5skdxvBT7Xxj7gIDCwoYZa6ze11kla66TQ0FAb7PrMXDbzLr5SFxC8+TUqD/7a7vsXQoj2YovkfhiYCKCU6gYMAA7YYLs2F+Djju9l/yLDEszxT26D8mJ7hySEEGdFS4ZCzgN+BQYopdKUUrcppX6rlPqttcnTwDlKqW3AD8BsrXXe2Qu5bSYm9mVhr8fpUprJ0Q9/A5YOdXpACCFswq25Blrr65pZnwFMtllE7eA311/Pf57fzB+OvEPpsr/jPfkv9g5JCCFsyqmvUG1MF083Jtz0OAss4/D+5V/onV/bOyQhhLCpTpncAWIjAzkx6Z9ssfSm7PM/wPEOW0kSQogz1mmTO8AN5w3gq+hHcKkooeStaVDSvsMzhRDibOnUyV0pxQM3XsmTXR7HrfAApfNuAku1vcMSQog269TJHcDX0427b7udf6jb8U7/hbJlf5PpgYUQDq/TJ3eAqK4+TLnhQT63nI/XL89jWfx/kuCFEA5NkrvVqD4hVFz8Cm9VTcNl/ZvoxQ9BxXF7hyWEEK0iyb2OmaNiKD7vCT6smoha/xb6vYvlIichhEOS5F7P/ZMHsH/kU/y76kpUxiZY8YyUaIQQDkeSez1KKR67JJaMhD/wZfU5sOqf8Msr9g5LCCHOiCT3Bri4KP4+YyjfD3iaRdWj4PvH4PvHpQcvhHAYktwb4eqiePG6YXw/4K98VDUBfv43eukjkLvH3qEJIUSzJLk3wd3VhReuH0Vy3BO8W3URau1/4LURkPK5vUMTQogmSXJvhquL4rmrE9k77C+8WDkDAL3iWSjOtnNkQgjROEnuLeDiovjbFXEcG/0n7qh4gMr8Q+g5F0Gq3M1JCNExSXJvIaUUj18ymH7nX8vMskcoKD6B/vBK2P+jvUMTQojTSHI/A0opHrpoABdNmc7kkic5YglFfzgDlj8jE44JITqUZu/EJE6llOKucX3oGezD5Z9483eP95iy8lnIToHpr4BPV3uHKIQQktxba0psOOEBE7j9fT82Vcfw8K7/ofZ+D+f8HsY/Cq7ypxVC2I+UZdogISqQL+4Zy8rAGUyreIY9IRPhp+fhg8uhJMfe4QkhOjFJ7m0UEejNgt+dQ68hI5mcegPvhj6ETlsP/z3fjIeXWrwQwg4kuduAr6cbr10/jMcvGczf0odxm9vfqKo4AfNvhS9/D2XH7B2iEKKTkeRuI0opfnNuLz65aww7dS9GH3+evVFXwZaP4L/nwZaPZW4aIUS7keRuY8N7BvHNH89jUK9oLtx7Ja9Gv4TFzQcW3gULboOyInuHKIToBJpN7kqpOUqpHKVUShNtxiulNiultiulVto2RMfT1deD924dyf2T+vP83jCmlv2NrOEPwfYv4LVR8NmtkL/f3mEKIZxYS3ru7wFTGluplAoEXgema62HAFfbJjTH5uqiuHdSPz74zSgKyiyM/XUYHw35L9VhQ2D75zDnIlj3FlRV2DtUIYQTaja5a61XAUebaHI98LnW+rC1vYwBrOPcfiF8f/84Lk+M4NFkH6bl3cuBqXOhS3dY/CC8NlLmqBFC2Jwtau79gSCl1Aql1Aal1E2NNVRK3amUSlZKJefm5tpg144hwMed569JYM4tSRSWVnDhly78q9dbVM78xDR4dwp8cQ9s+QSO59s3WCGEU1C6BSM4lFIxwCKtdWwD614FkoCJgDfwK3Cx1rrJu1okJSXp5OTkVoTs2IpKK3l60Q7mb0ijf7cuvDg9hiF734A1r5sGYYPhmvchuC8oZd9ghRAdjlJqg9Y6qbl2tui5pwFLtdbHtdZ5wCogwQbbdUoB3u48d3UC794ygmOlVUx/Zzv/5GbKb/8JJvwFjqXDq0lm+OT2hZC93d4hCyEckC2S+5fAeUopN6WUDzAK2GmD7Tq1CQPD+Pb+85kxLILXV+xn8rx8vgu5EX33Whj1W8jZCZ/dAm9NNPdv/eZBuRhKCNFizZZllFLzgPFACJANPAG4A2it37C2eQi4FbAAb2utX2pux521LNOQn/bm8tTXO9iXU8LYvsE8dslgBrrlwI6FsOF9KDpsGibOAncfiB4NcVfZN2ghhF20tCzTopr72SDJ/VSV1RbmrknlxWV7KS6r5PpR0Txw4QC6+rjD7iWw7VNTpqlxz3oI7W+/gIUQdiHJ3UEVHK/gpWV7+HDtYXzcXbl7Ql9uHRuDl7srpP4C+5fDhnehsgxizgUPX5jwKAT3sXfoQoh2IMndwe3NLubZJbv4YVcOEYHe/Glyfy6J74GHm4u5unXlPyFjE+TtBp9giBgO0WNg7H3gIrNKCOGsJLk7iV/25fG3xTvZnnGMHgFePDB5AFcMjcDVxTpMMnsHfPcX2P+Dee8VCG6eUF4MV74Fgy6xX/BCCJuT5O5ELBbN8t05/PuHvWxNK2Jgdz/um9SfSYPCcHN1qWkEKfPNHPIHlkNVGbh5w4jbzEnY0b+TWwAK4QQkuTshi0XzzbZM/vXtbg4fPUGfUF8enDyAKbHdUXUveKosheJMWHA7pG8wy8ITYOClMOxG8Otulu1fDt1ioUto+x+MEKJVJLk7scpqC9/vyOaF7/ewL6eEuIgA7p3YjwsGhuHiUu+q1spS2DYfvnkAqitM2SYgErr2gp1fQ0QS3PGDfQ5ECHHGJLl3AtUWzcJN6by0bA9pBaUM7O7HHyf2Y8qQ7qcn+epKOHoAlvwfHFhx6rpucRA5HHqeC7FXgotrux2DEOLMSHLvRCqrLXy9JYNXl+/jQO5xegb7cPOYGGaOjMLHw63hD+351iT53UvMydfyYqguh55jocdQM8wyIMr08F09oKocPLu063EJIU4nyb0TqrZolqRk8t7Ph0hOLaCrrwe3nduLWaOiCfTxaPrDFSdg3X9hw3tQlA6WSrPcxQ18w0xvfsY7Zlx999PmjxNCtBNJ7p3c+kNHefXHfazck4uXuwtXD4/ijvN6Ex3s0/yH8/aa8k3evtqpD+q6+n8w+DKZtVIIO5DkLgDYlXWMOasPsnBTOlUWzeTB3bjt3N6MiAk6dYRNYw6sgKI0WPIweAVA5QkoPQoDpkHYIBh5F/h1O+vHIYQwJLmLU2QfK+P9Xw8xd+1hCk9UEh8ZwN3j+zB5cAMnXxty4qhJ7gA/PQ+/vAIVJaZko1zMSJwx98DQG6G0QOa9EeIskeQuGlRaUc2CjWm8/dMBDuWfoHeILzefE8NVwyPx9Wzk5Gtj9nwHa98w4+aPZZiLpwBQMPBiOP8hc+XswEsl2QthI5LcRZOqqi18sy2TOT8fYsuRQvy93Lh2RBQ3jO5Jz2DfM9+gpRoW3AYlOeAXDju+rD0pC2Y8/aQnzIRnVWXQb7K5UXjcNeB6hl8qwnls/ACiRkLoAHtH4jAkuYsW25BawJzVB1m6PQuL1ozrH8pNY3oyvn8DF0W11OE1ZiqE6FGw6UNI3whlhbXr+0+FPUtM7/68B8Hd69TPnzgKHl2gqhSOHoQeia0/QNExWSzw1yAzPcafM+0djcOQ5C7OWPaxMj5ae5h56w6TU1xOTLAPN58Tw9VJUXQ505JNfSeOmjr96hdOXxcUAzHnmRO3180zwy+fDoG4q025J/VnmJ0K3oGQtQ28g8xVtsKxlRbCP3qa108W2TcWByLJXbRaZbWFpSlZvPvzQTYeLsTP040ZwyO5YXRP+oa18UImSzXk74Mja8FSZS6i2v+jeQ3g4g6B0XB0/6mfm/QUJMyE5weYm4jf/atZfjwffIPbFpOwj6MH4eVE82X+eL69o3EYktyFTWw5Usi7Px9k8bYsKqotnNs3hJvG9GTioG610w63VdoGyNkOnv6w7TPYtaj5z9y9BpLnwLo34YK/mPJOQ7SG9W9D/ykQGGWbeIVtpG+EtyaY/+6PHLF3NA5DkruwqbyScj5Zf4QP16SSWVRGRKA3N47pyTVJUXT1bebq1zO14yszymbv9+ZesYMvhy3zTCJvzG9/NqWa9W+bE3TeQRA6ELK2wlsXmLr+xMdsG6dom30/wIdXQpdu8OAee0fjMFqa3GWYgmiRkC6e3DOhL3ed35vvd2Tzv18P8eySXTz/3W6mJ0Rw3cgohvds4YVRzRk83TzqCk8wQy679obPboHeE+oMvQTeGAueAVBep3YbkWTq+QB5kjw6nNIC8+zubd84nJQkd3FG3FxdmBoXztS4cPZkFzN3TSqfJqexYGMa/cK6cOOYnlwxNAI/L3fb7tjFFc77k3kdc76psy+ZDV3CzGgLSzVs+Riyt9V+Jj3ZPAB2fgUpC8yvgNUvgH8EJF5v1pUXw97voHsChPS1bdyicSeTewumxBBnTMoyos1KyqtYsi2TD9eksiWtCF8PV6YnRnBZYg9G9epqm958S1RXQkk2/PSCmcly/4/mHrOunmbGSzA9+YJD5vVj+XA8B15JgsrjZsrjWxadOmfOgZUm+USNaHy/e76FwsMw8o6zdWTOaeW/YPn/gx7D4M7lzbcXgNTchZ1sOVLI+7+msnhbJqWV1QwK9+eq4ZFcNTySAG8b9+abY6mGgyvNCbtF90H2dtCW2vUJ15nx+AUHTd23JNss73cRjLgd+k4y47Ch6aF6TwY030acbumjsOY1U3K7a5W9o3EYNkvuSqk5wCVAjta60blelVIjgDXAtVrr+c3tWJK7cyurrObzjel8vP4wW9OKcFEwPaEHd5zfmyE9AuwTVHUVrHwWBkw1Uxtv/ADQ0Ot8mP4K/Duh8c/esticsN3/AxxaDQMvMSWeyhPwTIRpc/92M4LnnD+YE7qd2cLfQUUxXPth422+vMdc4BY6EO5Z236xOThbnlB9D3gVeL+JnbkC/wC+bWmAwrl5ubty/ahorh8Vzda0Qr7cnMFHaw/zxeYMhvTw59oRUUxP6NH8PPO25Opmhk0CRAyHcbPNGGufYHB1hwf3wnP9zLqae8/WeG/aqe9TFsA1bmaGzBr/m27G5/uGmhuS1/j2z1BWBGPvA/8e4GGtMWdshsJUGHAxnMgzpZ2okWd+XNvmQ/e4jnUJ/5aPmm9TXmKeq8pav5+tn0L/i2ontWup0kLI3AK9x7V+3x1ci8oySqkYYFFjPXel1H1AJTDC2k567uI0hScq+GJTOp8mp7Ej8xgebi5MHtyN60dGM6ZPcPvV5ptSXmymPUhbb25LOGg6rHgGfnn59LbuPqbnXt+QK8DdFzZ/aL44TtS5QKf/FBj/sOmt/q177XI3bzPVwqOZtcm/vozNsPrquNbkAAAX2ElEQVRFmP5ybTI7sh7emdTx7oXbWKlKa5j/Gxh+C/z8b/NLyC8c/rTrzLcfORLS1plfUNf878w+/+7FkLoaHkl3uDuMtdtQSKVUBHAFcAEmuTfV9k7gToDo6Oi27lo4mEAfD24Z24tbxvYiJb2I+RvS+GJzOou2ZtI71JfLrSdhWzVxma14+pnnqJG1vegL/woTnzAjdvZ8C2teN7V85QJJv4HYGfDexaatdxBsX1i7vRP1rrzcs9Q86qsqNc+HfzG1fjCJEMwXiIu7GQ204wvw6Qqjfgs//NVMydAWOxfB8VxIurX12zi81vytar6c63YYtT71BHVZkZkwbudX5hcStLznbrGYE+TB/cz7tHXmuSjtzGOu+WVWfqzh5H5otbnO4sKnTl9XcMiU385/qPbfSwdki6GQLwGztdbVzfW8tNZvAm+C6bnbYN/CQcVGBBAbEcDDUwfyzdZMPlybygvf7+HfP+zl/H4hzBgeyaRB3fBy7wA361aqdubKAVPMo+yYmTLBp6tZPuMdUz++5AX45VWT5Pd+Z6ZaGHYTTPizKf3U7a03ZPdScyes9A3mBO+Jo5CdAlGjwMuayA/+ZH5V1L3ReUkOfPcXGHbL6cM5Cw/DurfMfXF7TwC3OqWwT2aZ58aSe/pGcxI6sk5HsSTX/Lrw8DUJcO5VMO05M1oof785SV2jrNDEO+hS83esKWNpi/mVBOb+vC3x5T2m3HPl26cub80N3WumuygrMqWy+mq+rCc+AS4u5nXeXvPf4+PrTRktIun06zE6EFsk9yTgY2tiDwGmKaWqtNZf2GDbwsl5ubsyY3gkM4ZHkllUyvu/prJwYzq//2gT/l5uXJrQgxnDIxkaFdgxyjY1vPxPfR93lXmASfDQ8BWxl//H9DRjZ5gLq1zcrFfSboPNc2H9Ww3v70idE475e80XRV1Fh83EbDu+hPu2mYSatxuSboOv/mC+CH552UzGNqNecgTTK65JYnW9NcE8P7jXjDrSFniuL/j1gD/tNF8cYOrXAHOmmOGlNVb8A9b+x3z5xV0FJ6xj27WltuZeeQJWPGti7RLa8PFrXVvH//z2U9cpa3KvtM4g2m1ww9s45Xit01GXHWu63dH9EGL9pfBqvUpI3fMtHVCbk7vWulfNa6XUe5iauyR2ccbCA7yZPWUgD04ewC/781iwwVwcNXftYXqH+jJjWCRXDosgPMCBr2isuXAKILhP7evAKFNHT0s2pZ4+E8xJvy9+e3ppByBnR+1rF7fanmjhYXOCdcFt5r1fOBRn1bbd9hlc9rrpvddcRARmH/UTa03yBVPr37fM/BIBKM4wX0hYf4BXV5jnuokdan9dFKaaBF33WCqKa1+veMZsr9+F5mS1qydc9pq5hePWT08dwlqfsn4p/fj/4NdX4Y+bTfvNc2HCXxr+0qpRVmR+nYT0ry3P1C0rvZoE96xr+GT1iSaSu8UC6Nb9qrCRZpO7UmoeMB4IUUqlAU8A7gBa6zfOanSiU3J1UZzXL5Tz+oVSXFbJ4m2ZzN+Qxr++3c3z3+1m0qBuzBrdk7F9gnFzbeJ/XEcTMxYe3H3qslu+MXPtDL/ZzIiZcJ2ZNTNjkykTFBw0Nz7JToELnzZTMyy4zZygdfc2JYT6Ft0Pl74E++tcOFSYaurgAZGmfOPha/YB5qRw8ru15wVq7FrMyeReWW9djdyd1vVl8MHlp5aSyovNxWYnvxhy4et7a9e/OgJu/go+b+bisJrkffSAed69GL591LyOuwbCBpqEvfUTc4ewunXygkPw0dVmxNJ1H8GWT8wvnboOrGwkuTcxk+V7F5vrKh5p4AbzR9abL63As3vesdnkrrW+rqUb01rf0qZohKjHz8uda0dEc+2IaFLzj/Px+iN8sv4I3+3IJtTPk0viw7lyaCRxkXYaO3+2hQ0yD4DfrjZz63hYTziXFsBXfzR14Zo6e85sc6LxnD+aq3HfnmiS0IVPm6kaFt5lRvHkbK9N3mB65jWzccZdbXr3KQtMyeO6j+GdyafHtvsb8Akxr0uy4fM7a9fVn/un6MipiR3Mrw3/CDiWbt5XV566vrwI3mzBUMWamn3N32VbncF6R9aa3rm7lzn2+mWpfctqj0VrWFjnGGoc/hVGNbC8sZ57wSFzYhzMqJ4/Z5kv2tJCmDfTbC/pN3DJi80fWxvI3DLCYfQM9mX2lIHcO7EfK3bnsHBTOnPXHObdnw8RG+HP9IQeXBzfg4hABy7bNKV73KnvvYPg2g9OXTbhkVPf/z7ZJKGa5H9wlSlX5O0zM2UOnQUvDzWJ3d0X+k40pZttn5n2PYaakTBDLj91FNA5fzx1eGhacu15gbvXmi+hlxNrE/fBnxo+Jp/g2jZ1R82E9DcloKbKMTVq6uY1VxhnbKxd9/UfzUijKc+Y99s+q/1CAthb59Kc+tc21Ni1yIySqq+hmntVxekXw2WlmOkrjqw1iX3oDebL9iyT6QeEQysqreTLzel8mnyElPRjuLooxvQOtib68DO/6XdnUFlqeqk14+nXvmmGdiZcZ67eXf0ibPyfaTf9VTM6KG8fLPk/M0okPNFcDPZcv9O3fdcqM50AmF8W/4hpOpboc2p7uXWF9Icr/lt7QrcpNSd3XxsFuY2Ml1cujX9RhPQ35yXKizlZZmqOuw90GwK3L4M1b8DS2ebLd8zvzS+Euqb+03zBrnzWvK+5q1grydwyotM5nH+Cj9Yd5rvtWRzIO46nm4upz4+KZlTvYNvdXEQYx/PNCd+wQeaCpH4XwaxPT23zZAD4R0LXXpD6i7mAqzgLBk6DD2eYIZSLHzx924k3wOWv1V5s1GscoM0vD4BxD9cmSzAzhv70PPiG1Z7UDR1UW/Ovz8W9dsTMn7Ng+d/rXaimaDLRd4835ynGza6t7zcmcoS5KO7k36RtcxBJchedltaaDakFfL0lg4Wb0jlWVkWwrweXJvTg6qRIBnX3b/2Nv0XDSnJMiaX+6JD8/aZ85OZlhnCG1ylZFB4xJ3CfsvZiL3wavn8MrnzLjIt39zZj6vcsMdcKgLlrl4uLuYr46/sgPN5cVFZj1G8hd7cZdZO72/wCGXQp7PzalJiu+K856TzpKbOvwJ7mCyljs6nvR58D139stvWs9YTnJS+ZiefqamhZjW5xp049XVfYELi7gV8qZ0CSuxBAaUU1y3fnsHhbJt9tz6ai2kJUV2+uHBrJ5UMj6BVix6thhZG315SJQvubmrXbGcw3VF1pvljKi804+OG3ml8JYJZ/fgdMe95cl6C1GaVSoyb31Vw/UZxlev41o29WPWcuHut1HuTsNMMsz33AjOqJHm3OVdSM0AkZYK5kDogwvxj2LDW/aCxV8Jr1SucHdplS2JnOg1OPJHch6sktLmf57hy+2pzBz/vz0BoSogK5cmgE0xN6EGTr2wUK55axGVb+AwZMM6Nw3L0abrdprvkSsNFtHiW5C9GErKIyvt6Sweeb0tmZaU7Eju7dlamx4UyJ7U5IF097hyhEgyS5C9FCOzKO8fXWDL5NMSdiXRSM7RvC9IQeTIntbvtbBgrRBpLchThDWmt2ZRWzaGsGX2/J5PDREydH3EwaHMbU2PCOMZGZ6NQkuQvRBlprNh0p5ItN6SzelkVeSTne7q5Mje3O1LhwRvXuir/06IUdSHIXwka01qzel8fibVks2ppBcVkV3u6uTBwUxtVJUZzbN0TG0It2I8ldiLOgrLKaTYcL+XJzOst2ZpNXUkFXXw8mDQrjquFRjIgJ6lhTEwun0253YhKiM/Fyd2VMn2DG9AmmrLKaH3bm8P2OLJakZPFpchq9QnwZPyCUSYO6cU5HuXWg6JSk5y6EDZRWVPPF5nSWpmSx5kA+5VUWeof4MiW2O1Njw4mN8JdEL2xCyjJC2ElpRTXfbMtk4aY01hw4SrVFExHozeQh3ZgypDtJMV2lRi9aTZK7EB1AwfEKlu3M5tvtWazam0dFlYVQP0+GRwdxzYhIRvcOxsdDqqOi5SS5C9HBlJRXsXxXDktTslh78Ch5JeV08XRjdO+uXDU8inP7hdBFpigWzZDkLkQHVlFl4ae9uSxJyeLnfXlkFpWhFEwYEMb0hB6M6x8qc92IBsloGSE6MA83FyYO6sbEQd2oqrbw8/581hzI57PkNH7clYOLguE9g7hgYDcuGtKN3qFd7B2ycDDScxeiA7FYNFvTi/hxZzY/7Mphe8YxXBSM6RPMhAFhjOkTzJAeTnq/WNEiUpYRwglkFpXy1qqDrNqby76cEgBGxnTlgkFhTBrUjb5h0qPvbCS5C+FksorKWLQ1g4/WHuZA3nEAeof6MnFgGOf3DyU+MpAAb5nvxtlJchfCiWUWlbJsRzbf7chm7YGjVFRb8HBzYVz/UCYODGPcgFDCA7ztHaY4C2yW3JVSc4BLgBytdWwD62cBs61vS4Dfaa23NLdjSe5C2Mbx8io2pBbww85slu3MIb2wFFcXRWJUIBcO7sZFQ7rL7QSdiC2T+/mYpP1+I8n9HGCn1rpAKTUVeFJrPaq5HUtyF8L2tNZsSSvi+x1ZrN6bx5a0IgBCungyeUg3rhwawbDoILlBuAOzaVlGKRUDLGoouddrFwSkaK0jmtumJHchzr5Decf5fkc2KRlFLNmWRUW1BW93V6Yn9OCKYSbRe7i52DtMcQbsNc79NmCJjbcphGilmBBf7ji/NwB/u6KKr7dksDQli4Wb0/kk+Qgebi4kRAZwTVIUY/oEExnkY+eIha3YrOeulJoAvA6cq7XOb6TNncCdANHR0cNTU1NbEbIQoq2KyypZsTuXDakF/LQ3l/25ZvTNoHB/RvXqyhVDI4iLCJDyTQfUrmUZpVQ8sBCYqrXe05IApSwjRMdQbdH8uj+fLWmF/Lwvj+TUAiqqLEQEenPlsAgGdPfjvH6hMsyyg2i3soxSKhr4HLixpYldCNFxuLoozu0Xwrn9QrhnQl9yjpWxel8eCzel8+ryfdT0/xKiApk8uBsXx4UTI6NvOryWjJaZB4wHQoBs4AnAHUBr/YZS6m1gBlBTY6lqybeK9NyF6PgKT1SwM7OYn/flsXy3mQ4BoFeILxMGhDFjeAQDuvnh5ionZduLXMQkhLC5jMJSlqZksXpfHj/tzaWyWuOi4Jw+IYwfEMo5fUIY3MPf3mE6NUnuQoiz6ujxCpbtyGZ/XgkLN6aTU1wOmF79xXHhTBrcjYhAb0K6eMgtBm1IkrsQot1orcktLuezDWmsO3iUlXtyT64b0zuY28/rxZg+ctcpW5DkLoSwm+xjZWw6XMDe7BL+u+oAJeVVeLi5EBnkzfSEHlyWGCFTIrSSJHchRIdQXlXN+oMFrNidw+p9eezKKgYguqsP/bv5MaxnIDNHROPv5SYnZltAkrsQosPRWnP46Am+3Z7FxtRC9uWWnJynPszPk9lTBjKsZxAxwT5Sp2+EJHchhENYeyCfTUcK+XBNKmkFpQB08XRjSA9/Jg4K45qkKAJ95H6yNSS5CyEcSmW1hf25Jaw/VMCOjCLWHjzKgdzjeLu7csHAMOIiA4jtEUBcRAABPp33alm5QbYQwqG4u7owsLs/A7vXjpPfmXmMd38+yK8H8vlmWyYALgquGBrJ5CHdGBodSJifl71C7tCk5y6EcAiFJypIST/G11syWLg5nYoqC24uip7BPoztG8Kw6CAmD+mGt7urU9frpSwjhHBa5VXVJB8qYPW+PHZkHDs5rt7XwxUNTIntzhVDIzi3b4jTJXpJ7kKITuN4eRXJqQV8uSmdHZnHTg637BfWhXH9Q7kkoQcJkQFOkegluQshOq2yymq+3pLBZxvS2HykkIoqCwOsY+r7d/MjzM+LCwd3c8i7UElyF0IIoKi0km+2ZvLl5nR2ZByjuLwKgFA/T/qFdeHmc2KICvIhIsjbIeasl+QuhBD1FJVWsmxHNr6ernyWbObBqUn2vh6uXD8qmjA/L6KDfbhoSHc7R9swGQophBD1BHi7M2N4JABTYsMpq6zm5315lFVa+HZ7Fu+sPojF2t8N9fOku78X903qx7j+oQ43NYL03IUQwiqnuIzisire/ukAGYVl7MspIb2wFA83FwaH+3NpQg+G9PAnpIsHfcP87BKjlGWEEKKNSiuq+WFXNmsO5LPpcOHJO1EBjO0bzPUjexLm78mImK7tFpOUZYQQoo28PVy5JL4Hl8T3AOBQ3nH255ZwIPc4z323m5/35Z9sO7C7H7NG92RkTFf6hnXB1cW+wy6l5y6EEK2Qkl7E3LWHqaiysOlwAW6uij3ZZobL6K4+XD40ghtGRaOUouBEBf272aaMI2UZIYRoR9UWzfJdOeSVlLNgYxrrDxXg6qKotp6hvX9Sf/qGdWHioDC83F1bvR9J7kIIYUfJh47y0drDLEnJorSy+uTyIB937pnQl9vP692q7UrNXQgh7CgppitJMV154Vrz/kRFFWsPHmXRlkxC/TzP+v4luQshRDvw8XBjwoAwJgwIa5f9OdaofCGEEC3SbHJXSs1RSuUopVIaWa+UUi8rpfYppbYqpYbZPkwhhBBnoiU99/eAKU2snwr0sz7uBP7T9rCEEEK0RbPJXWu9CjjaRJPLgPe1sQYIVEqF2ypAIYQQZ84WNfcI4Eid92nWZadRSt2plEpWSiXn5ubaYNdCCCEaYovk3tA1tg0Ontdav6m1TtJaJ4WGhtpg10IIIRpii+SeBkTVeR8JZNhgu0IIIVrJFsn9K+Am66iZ0UCR1jrTBtsVQgjRSs1OP6CUmgeMB0KAbOAJwB1Aa/2GMnecfRUzouYEcKvWutl5BZRSuUBqK+MOAfJa+VlHJcfcOcgxdw5tOeaeWutm69p2m1umLZRSyS2ZW8GZyDF3DnLMnUN7HLNcoSqEEE5IkrsQQjghR03ub9o7ADuQY+4c5Jg7h7N+zA5ZcxdCCNE0R+25CyGEaIIkdyGEcEIOl9yVUlOUUrutUww/bO94bKWhqZWVUl2VUt8rpfZan4Osy51immWlVJRSarlSaqdSartS6l7rcqc9bqWUl1JqnVJqi/WYn7Iu76WUWms95k+UUh7W5Z7W9/us62PsGX9rKaVclVKblFKLrO+d+ngBlFKHlFLblFKblVLJ1mXt9m/boZK7UsoVeA0zzfBg4Dql1GD7RmUz73H61MoPAz9orfsBP1jfg/NMs1wF/ElrPQgYDdxj/e/pzMddDlygtU4AEoEp1iu7/wG8aD3mAuA2a/vbgAKtdV/gRWs7R3QvsLPOe2c/3hoTtNaJdca0t9+/ba21wzyAMcC3dd4/Ajxi77hseHwxQEqd97uBcOvrcGC39fV/gesaaufID+BL4MLOctyAD7ARGIW5WtHNuvzkv3PgW2CM9bWbtZ2yd+xneJyR1kR2AbAIM9mg0x5vneM+BITUW9Zu/7YdqufOGUwv7CS6aes8PdbnmpsvOt3fwfrzeyiwFic/bmuJYjOQA3wP7AcKtdZV1iZ1j+vkMVvXFwHB7Rtxm70E/B9gsb4PxrmPt4YGvlNKbVBK3Wld1m7/th3tBtktnl7YyTnV30Ep1QVYANyntT5mpitquGkDyxzuuLXW1UCiUioQWAgMaqiZ9dmhj1kpdQmQo7XeoJQaX7O4gaZOcbz1jNVaZyilwoDvlVK7mmhr8+N2tJ57Z5teOLvmrlbW5xzrcqf5Oyil3DGJfa7W+nPrYqc/bgCtdSGwAnO+IVApVdPZqntcJ4/Zuj6Apu+M1tGMBaYrpQ4BH2NKMy/hvMd7ktY6w/qcg/kSH0k7/tt2tOS+HuhnPdPuAczETDnsrL4Cbra+vhlTk65Z7vDTLCvTRX8H2Km1fqHOKqc9bqVUqLXHjlLKG5iEOdG4HLjK2qz+Mdf8La4CftTWoqwj0Fo/orWO1FrHYP5//VFrPQsnPd4aSilfpZRfzWtgMpBCe/7btvdJh1acpJgG7MHUKf9s73hseFzzgEygEvMtfhum1vgDsNf63NXaVmFGDe0HtgFJ9o6/lcd8Luan51Zgs/UxzZmPG4gHNlmPOQV43Lq8N7AO2Ad8Bnhal3tZ3++zru9t72Now7GPBxZ1huO1Ht8W62N7Ta5qz3/bMv2AEEI4IUcrywghhGgBSe5CCOGEJLkLIYQTkuQuhBBOSJK7EEI4IUnuQgjhhCS5CyGEE/r/2D33cuDEkaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
